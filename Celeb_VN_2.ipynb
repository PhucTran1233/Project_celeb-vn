{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Celeb_VN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPLMe7mL5303ZieVfIxjBzk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PhucTran1233/Project_celeb-vn/blob/main/Celeb_VN_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qIZjasVeOJaE",
        "outputId": "9a7f7dd6-1b00-43d6-901a-4c461068c5cc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "# liên kết Google drive với colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Tải thư viện cần thiết\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "from keras.preprocessing.image import load_img, img_to_array,array_to_img,ImageDataGenerator, image\n",
        "from keras.layers import Dense,Activation,Dropout,Conv2D,MaxPooling2D,Flatten\n",
        "from tensorflow.keras.models import load_model\n",
        "from keras.models import  Sequential\n",
        "from keras import regularizers\n",
        "from keras import layers"
      ],
      "metadata": {
        "id": "3hZC5QGYOPbN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = '/content/drive/MyDrive/AI/BaiTapCuoiKi_Celeb_VN/Train'\n",
        "val_data  =  '/content/drive/MyDrive/AI/BaiTapCuoiKi_Celeb_VN/Validation'"
      ],
      "metadata": {
        "id": "AZ_JhltXOYU8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch_sizes = 64\n",
        "image_size = 128\n",
        "#preprocessing\n",
        "train_scale = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range=0.2,\n",
        "                                   width_shift_range=0.2,   \n",
        "                                   height_shift_range=0.2,\n",
        "                                   shear_range=0.3,\n",
        "                                   zoom_range=0.5,\n",
        "                                   horizontal_flip=True, \n",
        "                                   vertical_flip=True,\n",
        "                                   validation_split=0.2)\n",
        "\n",
        "train_input = train_scale.flow_from_directory(train_data,\n",
        "                        target_size=(image_size, image_size),\n",
        "                        batch_size=batch_sizes,\n",
        "                        class_mode=\"categorical\")\n",
        "\n",
        "val_scale = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "val_input = val_scale.flow_from_directory(val_data,\n",
        "                        target_size=(image_size, image_size),\n",
        "                        batch_size=batch_sizes,\n",
        "                        class_mode=\"categorical\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ic4-4mZXOaY8",
        "outputId": "af2d50bd-4c9a-4af2-a04e-d668a3f9b56c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 1704 images belonging to 37 classes.\n",
            "Found 210 images belonging to 37 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"match class: \", train_input.class_indices)\n",
        "print(\"Tổng cộng: \",train_input.num_classes)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ahYwV1tOhwm",
        "outputId": "bc808c21-f09a-4f0f-b9b4-ebd7ef5d16a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "match class:  {'1-Ribi Sachi Thuỷ': 0, '10-Quang Thắng': 1, '11-Vũ Cát Tường': 2, '12-Ánh Viên': 3, '13-NSUT Hồng Vân': 4, '15-Misthy': 5, '16-Phạm Nhật Vượng': 6, '18-Karik': 7, '19-Nhật Anh Trắng': 8, '20-NSUT Tự Long': 9, '21-Sỹ Luân': 10, '22-MC Đại Nghĩa': 11, '26-Sơn Tùng MTP': 12, '27-ViruSs': 13, '28-Nguyễn Thị Kim Ngân': 14, '29-Thái Vũ': 15, '3-Nguyễn Huy Hoàng': 16, '30-Chí Tài': 17, '33-Huỳnh Phương': 18, '34-Lí Hải': 19, '35-Mạc Văn khoa': 20, '36-Phan Mạnh Quỳnh': 21, '38-Minh Nhí': 22, '39-Quang Hải': 23, '4-Đàm Vĩnh Hưng': 24, '41-Nguyễn Tử Quảng': 25, '42-Lê Quang Liêm': 26, '43-Tiên Tiên': 27, '44-MC Lại Văn Sâm': 28, '46-Đen Vâu': 29, '47-Vân Dung': 30, '48-Hà Anh Tuấn': 31, '49-Hoài Linh': 32, '5-TT Nguyễn Xuân Phúc': 33, '6-NSUT Quyền Linh': 34, '7-NSUT Xuân Bắc': 35, '8-PewPew': 36}\n",
            "Tổng cộng:  37\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#MODEL CNN\n",
        "model=Sequential()\n",
        "#TRÍCH XUẤT TẬP DỮ LIỆU(FEATURE EXTRACTORS)\n",
        "#LAYER 1\n",
        "model.add(Conv2D(16,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same',input_shape=(image_size,image_size,3)))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "#LAYER 2\n",
        "model.add(Conv2D(64,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "#LAYER 3\n",
        "model.add(Conv2D(256,(3,3),activation='relu',kernel_initializer='he_uniform',padding='same'))\n",
        "model.add(MaxPooling2D((2,2)))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "#FULLY CONNECTED LAYER\n",
        "#Flatten Layer is used to change the dimension of output from convolution layer, which has 3D, to 2D output\n",
        "model.add(Flatten())\n",
        "\n",
        "#Dense\n",
        "model.add(Dense(4096,activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(1024,activation='relu',kernel_regularizer=regularizers.l2(0.001)))\n",
        "model.add(Dropout(0.5))\n",
        "\n",
        "model.add(Dense(train_input.num_classes,activation='softmax'))  \n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jh4YEN2tOmYm",
        "outputId": "2f7b1e91-75a3-4e80-9626-12c97d86812c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 128, 128, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 64, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64, 64, 16)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 64, 64, 64)        9280      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 32, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 256)       147712    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 16, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 65536)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              268439552 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              4195328   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 37)                37925     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 272,830,245\n",
            "Trainable params: 272,830,245\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.optimizers import Adam\n",
        "opt = Adam(learning_rate=0.001)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "MC6VTFozOrQM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "ckpoint = ModelCheckpoint(\"Best_facecelb_model_val.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"max\", verbose=1)"
      ],
      "metadata": {
        "id": "7P5SAwngOwFR"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "face_celeb_train = model.fit(train_input,batch_size=batch_sizes,epochs=500,verbose=1,validation_data=val_input,callbacks=ckpoint)"
      ],
      "metadata": {
        "id": "n63ZUbBPO3dC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173c64f1-794e-4754-92cf-cc3836f9adfd"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 38.3887 - accuracy: 0.0305 \n",
            "Epoch 1: val_accuracy improved from -inf to 0.02857, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 1079s 41s/step - loss: 38.3887 - accuracy: 0.0305 - val_loss: 16.0041 - val_accuracy: 0.0286\n",
            "Epoch 2/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 15.1695 - accuracy: 0.0446\n",
            "Epoch 2: val_accuracy improved from 0.02857 to 0.03333, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 981ms/step - loss: 15.1695 - accuracy: 0.0446 - val_loss: 14.0691 - val_accuracy: 0.0333\n",
            "Epoch 3/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 13.1072 - accuracy: 0.0381\n",
            "Epoch 3: val_accuracy improved from 0.03333 to 0.04286, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 982ms/step - loss: 13.1072 - accuracy: 0.0381 - val_loss: 12.1752 - val_accuracy: 0.0429\n",
            "Epoch 4/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 11.4013 - accuracy: 0.0428\n",
            "Epoch 4: val_accuracy did not improve from 0.04286\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 11.4013 - accuracy: 0.0428 - val_loss: 10.7277 - val_accuracy: 0.0286\n",
            "Epoch 5/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 10.1113 - accuracy: 0.0458\n",
            "Epoch 5: val_accuracy did not improve from 0.04286\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 10.1113 - accuracy: 0.0458 - val_loss: 9.6235 - val_accuracy: 0.0238\n",
            "Epoch 6/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 9.1079 - accuracy: 0.0446\n",
            "Epoch 6: val_accuracy did not improve from 0.04286\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 9.1079 - accuracy: 0.0446 - val_loss: 8.7252 - val_accuracy: 0.0286\n",
            "Epoch 7/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 8.2907 - accuracy: 0.0481\n",
            "Epoch 7: val_accuracy did not improve from 0.04286\n",
            "27/27 [==============================] - 11s 405ms/step - loss: 8.2907 - accuracy: 0.0481 - val_loss: 8.0104 - val_accuracy: 0.0286\n",
            "Epoch 8/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 7.6275 - accuracy: 0.0581\n",
            "Epoch 8: val_accuracy did not improve from 0.04286\n",
            "27/27 [==============================] - 11s 408ms/step - loss: 7.6275 - accuracy: 0.0581 - val_loss: 7.4175 - val_accuracy: 0.0286\n",
            "Epoch 9/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 7.0890 - accuracy: 0.0581\n",
            "Epoch 9: val_accuracy improved from 0.04286 to 0.04762, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 25s 961ms/step - loss: 7.0890 - accuracy: 0.0581 - val_loss: 6.9264 - val_accuracy: 0.0476\n",
            "Epoch 10/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 6.6294 - accuracy: 0.0622\n",
            "Epoch 10: val_accuracy improved from 0.04762 to 0.05238, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 27s 998ms/step - loss: 6.6294 - accuracy: 0.0622 - val_loss: 6.5315 - val_accuracy: 0.0524\n",
            "Epoch 11/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 6.2651 - accuracy: 0.0734\n",
            "Epoch 11: val_accuracy did not improve from 0.05238\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 6.2651 - accuracy: 0.0734 - val_loss: 6.1683 - val_accuracy: 0.0476\n",
            "Epoch 12/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 5.9447 - accuracy: 0.0839\n",
            "Epoch 12: val_accuracy did not improve from 0.05238\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 5.9447 - accuracy: 0.0839 - val_loss: 5.9163 - val_accuracy: 0.0476\n",
            "Epoch 13/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 5.6906 - accuracy: 0.0886\n",
            "Epoch 13: val_accuracy improved from 0.05238 to 0.05714, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 988ms/step - loss: 5.6906 - accuracy: 0.0886 - val_loss: 5.6752 - val_accuracy: 0.0571\n",
            "Epoch 14/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 5.4571 - accuracy: 0.0933\n",
            "Epoch 14: val_accuracy did not improve from 0.05714\n",
            "27/27 [==============================] - 11s 404ms/step - loss: 5.4571 - accuracy: 0.0933 - val_loss: 5.4752 - val_accuracy: 0.0571\n",
            "Epoch 15/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 5.2807 - accuracy: 0.0822\n",
            "Epoch 15: val_accuracy improved from 0.05714 to 0.07619, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 25s 951ms/step - loss: 5.2807 - accuracy: 0.0822 - val_loss: 5.2654 - val_accuracy: 0.0762\n",
            "Epoch 16/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 5.0915 - accuracy: 0.0992\n",
            "Epoch 16: val_accuracy did not improve from 0.07619\n",
            "27/27 [==============================] - 11s 405ms/step - loss: 5.0915 - accuracy: 0.0992 - val_loss: 5.1343 - val_accuracy: 0.0476\n",
            "Epoch 17/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.9637 - accuracy: 0.0945\n",
            "Epoch 17: val_accuracy improved from 0.07619 to 0.08095, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 25s 953ms/step - loss: 4.9637 - accuracy: 0.0945 - val_loss: 4.9845 - val_accuracy: 0.0810\n",
            "Epoch 18/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.8490 - accuracy: 0.0898\n",
            "Epoch 18: val_accuracy did not improve from 0.08095\n",
            "27/27 [==============================] - 11s 402ms/step - loss: 4.8490 - accuracy: 0.0898 - val_loss: 4.9241 - val_accuracy: 0.0571\n",
            "Epoch 19/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.7443 - accuracy: 0.0962\n",
            "Epoch 19: val_accuracy did not improve from 0.08095\n",
            "27/27 [==============================] - 11s 406ms/step - loss: 4.7443 - accuracy: 0.0962 - val_loss: 4.8197 - val_accuracy: 0.0714\n",
            "Epoch 20/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.6583 - accuracy: 0.1115\n",
            "Epoch 20: val_accuracy improved from 0.08095 to 0.08571, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 25s 946ms/step - loss: 4.6583 - accuracy: 0.1115 - val_loss: 4.7183 - val_accuracy: 0.0857\n",
            "Epoch 21/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.5996 - accuracy: 0.1068\n",
            "Epoch 21: val_accuracy improved from 0.08571 to 0.09048, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 977ms/step - loss: 4.5996 - accuracy: 0.1068 - val_loss: 4.6683 - val_accuracy: 0.0905\n",
            "Epoch 22/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.5427 - accuracy: 0.1086\n",
            "Epoch 22: val_accuracy improved from 0.09048 to 0.09524, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 988ms/step - loss: 4.5427 - accuracy: 0.1086 - val_loss: 4.5733 - val_accuracy: 0.0952\n",
            "Epoch 23/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.4831 - accuracy: 0.1033\n",
            "Epoch 23: val_accuracy improved from 0.09524 to 0.10952, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 978ms/step - loss: 4.4831 - accuracy: 0.1033 - val_loss: 4.5364 - val_accuracy: 0.1095\n",
            "Epoch 24/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.4485 - accuracy: 0.1092\n",
            "Epoch 24: val_accuracy did not improve from 0.10952\n",
            "27/27 [==============================] - 11s 407ms/step - loss: 4.4485 - accuracy: 0.1092 - val_loss: 4.5046 - val_accuracy: 0.0762\n",
            "Epoch 25/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.3928 - accuracy: 0.0951\n",
            "Epoch 25: val_accuracy improved from 0.10952 to 0.12381, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 25s 949ms/step - loss: 4.3928 - accuracy: 0.0951 - val_loss: 4.4195 - val_accuracy: 0.1238\n",
            "Epoch 26/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.3354 - accuracy: 0.1127\n",
            "Epoch 26: val_accuracy did not improve from 0.12381\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 4.3354 - accuracy: 0.1127 - val_loss: 4.3667 - val_accuracy: 0.1000\n",
            "Epoch 27/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.3054 - accuracy: 0.1127\n",
            "Epoch 27: val_accuracy did not improve from 0.12381\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 4.3054 - accuracy: 0.1127 - val_loss: 4.3377 - val_accuracy: 0.1048\n",
            "Epoch 28/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.2564 - accuracy: 0.1262\n",
            "Epoch 28: val_accuracy improved from 0.12381 to 0.16667, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 25s 958ms/step - loss: 4.2564 - accuracy: 0.1262 - val_loss: 4.3100 - val_accuracy: 0.1667\n",
            "Epoch 29/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.2410 - accuracy: 0.1285\n",
            "Epoch 29: val_accuracy did not improve from 0.16667\n",
            "27/27 [==============================] - 11s 406ms/step - loss: 4.2410 - accuracy: 0.1285 - val_loss: 4.3176 - val_accuracy: 0.1333\n",
            "Epoch 30/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.2321 - accuracy: 0.1203\n",
            "Epoch 30: val_accuracy did not improve from 0.16667\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 4.2321 - accuracy: 0.1203 - val_loss: 4.3772 - val_accuracy: 0.1190\n",
            "Epoch 31/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.2515 - accuracy: 0.1180\n",
            "Epoch 31: val_accuracy did not improve from 0.16667\n",
            "27/27 [==============================] - 11s 406ms/step - loss: 4.2515 - accuracy: 0.1180 - val_loss: 4.2493 - val_accuracy: 0.1238\n",
            "Epoch 32/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.2020 - accuracy: 0.1174\n",
            "Epoch 32: val_accuracy did not improve from 0.16667\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 4.2020 - accuracy: 0.1174 - val_loss: 4.2279 - val_accuracy: 0.1048\n",
            "Epoch 33/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.1504 - accuracy: 0.1262\n",
            "Epoch 33: val_accuracy did not improve from 0.16667\n",
            "27/27 [==============================] - 11s 406ms/step - loss: 4.1504 - accuracy: 0.1262 - val_loss: 4.2041 - val_accuracy: 0.1143\n",
            "Epoch 34/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.1499 - accuracy: 0.1268\n",
            "Epoch 34: val_accuracy did not improve from 0.16667\n",
            "27/27 [==============================] - 11s 405ms/step - loss: 4.1499 - accuracy: 0.1268 - val_loss: 4.1691 - val_accuracy: 0.1095\n",
            "Epoch 35/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.1364 - accuracy: 0.1408\n",
            "Epoch 35: val_accuracy did not improve from 0.16667\n",
            "27/27 [==============================] - 11s 405ms/step - loss: 4.1364 - accuracy: 0.1408 - val_loss: 4.1608 - val_accuracy: 0.1190\n",
            "Epoch 36/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.1266 - accuracy: 0.1273\n",
            "Epoch 36: val_accuracy did not improve from 0.16667\n",
            "27/27 [==============================] - 11s 405ms/step - loss: 4.1266 - accuracy: 0.1273 - val_loss: 4.0929 - val_accuracy: 0.1571\n",
            "Epoch 37/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.1088 - accuracy: 0.1397\n",
            "Epoch 37: val_accuracy did not improve from 0.16667\n",
            "27/27 [==============================] - 11s 406ms/step - loss: 4.1088 - accuracy: 0.1397 - val_loss: 4.1398 - val_accuracy: 0.1381\n",
            "Epoch 38/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.1024 - accuracy: 0.1473\n",
            "Epoch 38: val_accuracy improved from 0.16667 to 0.18095, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 25s 954ms/step - loss: 4.1024 - accuracy: 0.1473 - val_loss: 4.1340 - val_accuracy: 0.1810\n",
            "Epoch 39/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.1099 - accuracy: 0.1338\n",
            "Epoch 39: val_accuracy did not improve from 0.18095\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 4.1099 - accuracy: 0.1338 - val_loss: 4.2263 - val_accuracy: 0.0952\n",
            "Epoch 40/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.0508 - accuracy: 0.1491\n",
            "Epoch 40: val_accuracy did not improve from 0.18095\n",
            "27/27 [==============================] - 11s 407ms/step - loss: 4.0508 - accuracy: 0.1491 - val_loss: 4.0978 - val_accuracy: 0.1571\n",
            "Epoch 41/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.0915 - accuracy: 0.1461\n",
            "Epoch 41: val_accuracy did not improve from 0.18095\n",
            "27/27 [==============================] - 13s 467ms/step - loss: 4.0915 - accuracy: 0.1461 - val_loss: 4.1259 - val_accuracy: 0.1238\n",
            "Epoch 42/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.0640 - accuracy: 0.1567\n",
            "Epoch 42: val_accuracy did not improve from 0.18095\n",
            "27/27 [==============================] - 11s 407ms/step - loss: 4.0640 - accuracy: 0.1567 - val_loss: 4.1236 - val_accuracy: 0.1571\n",
            "Epoch 43/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.0962 - accuracy: 0.1362\n",
            "Epoch 43: val_accuracy did not improve from 0.18095\n",
            "27/27 [==============================] - 11s 403ms/step - loss: 4.0962 - accuracy: 0.1362 - val_loss: 4.1207 - val_accuracy: 0.1476\n",
            "Epoch 44/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.0542 - accuracy: 0.1420\n",
            "Epoch 44: val_accuracy did not improve from 0.18095\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 4.0542 - accuracy: 0.1420 - val_loss: 4.0942 - val_accuracy: 0.1095\n",
            "Epoch 45/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.0115 - accuracy: 0.1408\n",
            "Epoch 45: val_accuracy did not improve from 0.18095\n",
            "27/27 [==============================] - 11s 407ms/step - loss: 4.0115 - accuracy: 0.1408 - val_loss: 4.0352 - val_accuracy: 0.1524\n",
            "Epoch 46/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.0240 - accuracy: 0.1450\n",
            "Epoch 46: val_accuracy did not improve from 0.18095\n",
            "27/27 [==============================] - 11s 407ms/step - loss: 4.0240 - accuracy: 0.1450 - val_loss: 4.0871 - val_accuracy: 0.1524\n",
            "Epoch 47/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.0024 - accuracy: 0.1673\n",
            "Epoch 47: val_accuracy improved from 0.18095 to 0.18571, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 993ms/step - loss: 4.0024 - accuracy: 0.1673 - val_loss: 4.0088 - val_accuracy: 0.1857\n",
            "Epoch 48/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.0186 - accuracy: 0.1444\n",
            "Epoch 48: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 404ms/step - loss: 4.0186 - accuracy: 0.1444 - val_loss: 4.0255 - val_accuracy: 0.1571\n",
            "Epoch 49/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.0036 - accuracy: 0.1543\n",
            "Epoch 49: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 405ms/step - loss: 4.0036 - accuracy: 0.1543 - val_loss: 4.2782 - val_accuracy: 0.1333\n",
            "Epoch 50/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.0239 - accuracy: 0.1426\n",
            "Epoch 50: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 404ms/step - loss: 4.0239 - accuracy: 0.1426 - val_loss: 4.3252 - val_accuracy: 0.1048\n",
            "Epoch 51/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.9858 - accuracy: 0.1719\n",
            "Epoch 51: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.9858 - accuracy: 0.1719 - val_loss: 4.3077 - val_accuracy: 0.1286\n",
            "Epoch 52/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.9699 - accuracy: 0.1649\n",
            "Epoch 52: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.9699 - accuracy: 0.1649 - val_loss: 4.3426 - val_accuracy: 0.1095\n",
            "Epoch 53/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.9776 - accuracy: 0.1602\n",
            "Epoch 53: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 407ms/step - loss: 3.9776 - accuracy: 0.1602 - val_loss: 4.2728 - val_accuracy: 0.1333\n",
            "Epoch 54/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 4.0021 - accuracy: 0.1626\n",
            "Epoch 54: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 407ms/step - loss: 4.0021 - accuracy: 0.1626 - val_loss: 4.3961 - val_accuracy: 0.1238\n",
            "Epoch 55/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.9679 - accuracy: 0.1649\n",
            "Epoch 55: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 408ms/step - loss: 3.9679 - accuracy: 0.1649 - val_loss: 4.5213 - val_accuracy: 0.1333\n",
            "Epoch 56/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.9958 - accuracy: 0.1649\n",
            "Epoch 56: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 407ms/step - loss: 3.9958 - accuracy: 0.1649 - val_loss: 4.1731 - val_accuracy: 0.1333\n",
            "Epoch 57/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.9700 - accuracy: 0.1690\n",
            "Epoch 57: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.9700 - accuracy: 0.1690 - val_loss: 4.5379 - val_accuracy: 0.1048\n",
            "Epoch 58/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.9592 - accuracy: 0.1590\n",
            "Epoch 58: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 403ms/step - loss: 3.9592 - accuracy: 0.1590 - val_loss: 4.8125 - val_accuracy: 0.1238\n",
            "Epoch 59/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.9660 - accuracy: 0.1573\n",
            "Epoch 59: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.9660 - accuracy: 0.1573 - val_loss: 4.1443 - val_accuracy: 0.1524\n",
            "Epoch 60/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.9547 - accuracy: 0.1749\n",
            "Epoch 60: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.9547 - accuracy: 0.1749 - val_loss: 4.3023 - val_accuracy: 0.1381\n",
            "Epoch 61/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.9408 - accuracy: 0.1702\n",
            "Epoch 61: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 407ms/step - loss: 3.9408 - accuracy: 0.1702 - val_loss: 4.7757 - val_accuracy: 0.1143\n",
            "Epoch 62/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.9467 - accuracy: 0.1684\n",
            "Epoch 62: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 414ms/step - loss: 3.9467 - accuracy: 0.1684 - val_loss: 4.4235 - val_accuracy: 0.1333\n",
            "Epoch 63/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.9398 - accuracy: 0.1614\n",
            "Epoch 63: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 408ms/step - loss: 3.9398 - accuracy: 0.1614 - val_loss: 4.4034 - val_accuracy: 0.1571\n",
            "Epoch 64/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8729 - accuracy: 0.1825\n",
            "Epoch 64: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.8729 - accuracy: 0.1825 - val_loss: 4.8136 - val_accuracy: 0.1143\n",
            "Epoch 65/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.9660 - accuracy: 0.1643\n",
            "Epoch 65: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 408ms/step - loss: 3.9660 - accuracy: 0.1643 - val_loss: 4.1982 - val_accuracy: 0.1524\n",
            "Epoch 66/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.9223 - accuracy: 0.1684\n",
            "Epoch 66: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.9223 - accuracy: 0.1684 - val_loss: 4.7865 - val_accuracy: 0.1190\n",
            "Epoch 67/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.9060 - accuracy: 0.1878\n",
            "Epoch 67: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.9060 - accuracy: 0.1878 - val_loss: 4.2775 - val_accuracy: 0.1333\n",
            "Epoch 68/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.9607 - accuracy: 0.1749\n",
            "Epoch 68: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 404ms/step - loss: 3.9607 - accuracy: 0.1749 - val_loss: 4.1627 - val_accuracy: 0.1286\n",
            "Epoch 69/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.9229 - accuracy: 0.1819\n",
            "Epoch 69: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.9229 - accuracy: 0.1819 - val_loss: 4.3797 - val_accuracy: 0.1286\n",
            "Epoch 70/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8714 - accuracy: 0.1931\n",
            "Epoch 70: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 406ms/step - loss: 3.8714 - accuracy: 0.1931 - val_loss: 4.1119 - val_accuracy: 0.1286\n",
            "Epoch 71/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8925 - accuracy: 0.1872\n",
            "Epoch 71: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 408ms/step - loss: 3.8925 - accuracy: 0.1872 - val_loss: 4.4941 - val_accuracy: 0.1333\n",
            "Epoch 72/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8560 - accuracy: 0.1925\n",
            "Epoch 72: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 407ms/step - loss: 3.8560 - accuracy: 0.1925 - val_loss: 4.3803 - val_accuracy: 0.0952\n",
            "Epoch 73/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.9063 - accuracy: 0.1825\n",
            "Epoch 73: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 405ms/step - loss: 3.9063 - accuracy: 0.1825 - val_loss: 4.4155 - val_accuracy: 0.1524\n",
            "Epoch 74/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8584 - accuracy: 0.1978\n",
            "Epoch 74: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.8584 - accuracy: 0.1978 - val_loss: 4.5859 - val_accuracy: 0.1286\n",
            "Epoch 75/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8787 - accuracy: 0.1878\n",
            "Epoch 75: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 408ms/step - loss: 3.8787 - accuracy: 0.1878 - val_loss: 4.2437 - val_accuracy: 0.1429\n",
            "Epoch 76/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8606 - accuracy: 0.1948\n",
            "Epoch 76: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.8606 - accuracy: 0.1948 - val_loss: 4.3734 - val_accuracy: 0.1333\n",
            "Epoch 77/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8778 - accuracy: 0.1919\n",
            "Epoch 77: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.8778 - accuracy: 0.1919 - val_loss: 4.1939 - val_accuracy: 0.1619\n",
            "Epoch 78/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8232 - accuracy: 0.1984\n",
            "Epoch 78: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 407ms/step - loss: 3.8232 - accuracy: 0.1984 - val_loss: 4.3136 - val_accuracy: 0.1476\n",
            "Epoch 79/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8973 - accuracy: 0.1796\n",
            "Epoch 79: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.8973 - accuracy: 0.1796 - val_loss: 4.1783 - val_accuracy: 0.1714\n",
            "Epoch 80/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8888 - accuracy: 0.2031\n",
            "Epoch 80: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 405ms/step - loss: 3.8888 - accuracy: 0.2031 - val_loss: 4.2802 - val_accuracy: 0.1333\n",
            "Epoch 81/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8971 - accuracy: 0.2007\n",
            "Epoch 81: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 407ms/step - loss: 3.8971 - accuracy: 0.2007 - val_loss: 4.1212 - val_accuracy: 0.1381\n",
            "Epoch 82/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8326 - accuracy: 0.2124\n",
            "Epoch 82: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 408ms/step - loss: 3.8326 - accuracy: 0.2124 - val_loss: 4.1626 - val_accuracy: 0.1667\n",
            "Epoch 83/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8549 - accuracy: 0.2072\n",
            "Epoch 83: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 12s 452ms/step - loss: 3.8549 - accuracy: 0.2072 - val_loss: 4.3163 - val_accuracy: 0.1619\n",
            "Epoch 84/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8000 - accuracy: 0.2013\n",
            "Epoch 84: val_accuracy did not improve from 0.18571\n",
            "27/27 [==============================] - 11s 406ms/step - loss: 3.8000 - accuracy: 0.2013 - val_loss: 4.2972 - val_accuracy: 0.1571\n",
            "Epoch 85/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8165 - accuracy: 0.1872\n",
            "Epoch 85: val_accuracy improved from 0.18571 to 0.20000, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 25s 959ms/step - loss: 3.8165 - accuracy: 0.1872 - val_loss: 3.9568 - val_accuracy: 0.2000\n",
            "Epoch 86/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8300 - accuracy: 0.2019\n",
            "Epoch 86: val_accuracy did not improve from 0.20000\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.8300 - accuracy: 0.2019 - val_loss: 4.1716 - val_accuracy: 0.1571\n",
            "Epoch 87/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8635 - accuracy: 0.1966\n",
            "Epoch 87: val_accuracy did not improve from 0.20000\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.8635 - accuracy: 0.1966 - val_loss: 4.1168 - val_accuracy: 0.1619\n",
            "Epoch 88/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7964 - accuracy: 0.2207\n",
            "Epoch 88: val_accuracy did not improve from 0.20000\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.7964 - accuracy: 0.2207 - val_loss: 4.1424 - val_accuracy: 0.1714\n",
            "Epoch 89/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8261 - accuracy: 0.2224\n",
            "Epoch 89: val_accuracy did not improve from 0.20000\n",
            "27/27 [==============================] - 11s 408ms/step - loss: 3.8261 - accuracy: 0.2224 - val_loss: 4.0372 - val_accuracy: 0.1952\n",
            "Epoch 90/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8097 - accuracy: 0.2031\n",
            "Epoch 90: val_accuracy did not improve from 0.20000\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.8097 - accuracy: 0.2031 - val_loss: 4.0608 - val_accuracy: 0.1762\n",
            "Epoch 91/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8142 - accuracy: 0.2218\n",
            "Epoch 91: val_accuracy improved from 0.20000 to 0.21429, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 963ms/step - loss: 3.8142 - accuracy: 0.2218 - val_loss: 3.9284 - val_accuracy: 0.2143\n",
            "Epoch 92/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8038 - accuracy: 0.2183\n",
            "Epoch 92: val_accuracy did not improve from 0.21429\n",
            "27/27 [==============================] - 11s 405ms/step - loss: 3.8038 - accuracy: 0.2183 - val_loss: 4.0886 - val_accuracy: 0.2048\n",
            "Epoch 93/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8448 - accuracy: 0.2113\n",
            "Epoch 93: val_accuracy improved from 0.21429 to 0.22381, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 25s 961ms/step - loss: 3.8448 - accuracy: 0.2113 - val_loss: 3.9903 - val_accuracy: 0.2238\n",
            "Epoch 94/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8420 - accuracy: 0.2259\n",
            "Epoch 94: val_accuracy improved from 0.22381 to 0.24762, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 25s 960ms/step - loss: 3.8420 - accuracy: 0.2259 - val_loss: 3.9251 - val_accuracy: 0.2476\n",
            "Epoch 95/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8891 - accuracy: 0.2271\n",
            "Epoch 95: val_accuracy did not improve from 0.24762\n",
            "27/27 [==============================] - 11s 403ms/step - loss: 3.8891 - accuracy: 0.2271 - val_loss: 3.9462 - val_accuracy: 0.2095\n",
            "Epoch 96/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8219 - accuracy: 0.2300\n",
            "Epoch 96: val_accuracy did not improve from 0.24762\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.8219 - accuracy: 0.2300 - val_loss: 4.1965 - val_accuracy: 0.2095\n",
            "Epoch 97/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8387 - accuracy: 0.2271\n",
            "Epoch 97: val_accuracy did not improve from 0.24762\n",
            "27/27 [==============================] - 11s 408ms/step - loss: 3.8387 - accuracy: 0.2271 - val_loss: 3.9400 - val_accuracy: 0.2333\n",
            "Epoch 98/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8343 - accuracy: 0.2148\n",
            "Epoch 98: val_accuracy did not improve from 0.24762\n",
            "27/27 [==============================] - 11s 407ms/step - loss: 3.8343 - accuracy: 0.2148 - val_loss: 3.9621 - val_accuracy: 0.2238\n",
            "Epoch 99/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8591 - accuracy: 0.2072\n",
            "Epoch 99: val_accuracy improved from 0.24762 to 0.26190, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 963ms/step - loss: 3.8591 - accuracy: 0.2072 - val_loss: 3.8701 - val_accuracy: 0.2619\n",
            "Epoch 100/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8062 - accuracy: 0.2353\n",
            "Epoch 100: val_accuracy did not improve from 0.26190\n",
            "27/27 [==============================] - 13s 466ms/step - loss: 3.8062 - accuracy: 0.2353 - val_loss: 3.8761 - val_accuracy: 0.2619\n",
            "Epoch 101/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7800 - accuracy: 0.2430\n",
            "Epoch 101: val_accuracy did not improve from 0.26190\n",
            "27/27 [==============================] - 11s 408ms/step - loss: 3.7800 - accuracy: 0.2430 - val_loss: 3.9134 - val_accuracy: 0.2381\n",
            "Epoch 102/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8139 - accuracy: 0.2336\n",
            "Epoch 102: val_accuracy did not improve from 0.26190\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.8139 - accuracy: 0.2336 - val_loss: 3.8895 - val_accuracy: 0.2333\n",
            "Epoch 103/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7923 - accuracy: 0.2359\n",
            "Epoch 103: val_accuracy did not improve from 0.26190\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.7923 - accuracy: 0.2359 - val_loss: 3.8505 - val_accuracy: 0.2381\n",
            "Epoch 104/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7636 - accuracy: 0.2300\n",
            "Epoch 104: val_accuracy improved from 0.26190 to 0.29048, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 968ms/step - loss: 3.7636 - accuracy: 0.2300 - val_loss: 3.7686 - val_accuracy: 0.2905\n",
            "Epoch 105/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8014 - accuracy: 0.2388\n",
            "Epoch 105: val_accuracy did not improve from 0.29048\n",
            "27/27 [==============================] - 11s 406ms/step - loss: 3.8014 - accuracy: 0.2388 - val_loss: 3.8336 - val_accuracy: 0.2619\n",
            "Epoch 106/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7676 - accuracy: 0.2447\n",
            "Epoch 106: val_accuracy did not improve from 0.29048\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.7676 - accuracy: 0.2447 - val_loss: 3.7491 - val_accuracy: 0.2667\n",
            "Epoch 107/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7785 - accuracy: 0.2494\n",
            "Epoch 107: val_accuracy improved from 0.29048 to 0.32381, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 977ms/step - loss: 3.7785 - accuracy: 0.2494 - val_loss: 3.7910 - val_accuracy: 0.3238\n",
            "Epoch 108/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.8104 - accuracy: 0.2388\n",
            "Epoch 108: val_accuracy did not improve from 0.32381\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.8104 - accuracy: 0.2388 - val_loss: 3.8919 - val_accuracy: 0.2476\n",
            "Epoch 109/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7421 - accuracy: 0.2394\n",
            "Epoch 109: val_accuracy did not improve from 0.32381\n",
            "27/27 [==============================] - 11s 407ms/step - loss: 3.7421 - accuracy: 0.2394 - val_loss: 3.7652 - val_accuracy: 0.2619\n",
            "Epoch 110/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7624 - accuracy: 0.2441\n",
            "Epoch 110: val_accuracy did not improve from 0.32381\n",
            "27/27 [==============================] - 11s 414ms/step - loss: 3.7624 - accuracy: 0.2441 - val_loss: 3.9123 - val_accuracy: 0.2476\n",
            "Epoch 111/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7485 - accuracy: 0.2547\n",
            "Epoch 111: val_accuracy did not improve from 0.32381\n",
            "27/27 [==============================] - 11s 408ms/step - loss: 3.7485 - accuracy: 0.2547 - val_loss: 3.8727 - val_accuracy: 0.2857\n",
            "Epoch 112/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7463 - accuracy: 0.2418\n",
            "Epoch 112: val_accuracy did not improve from 0.32381\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.7463 - accuracy: 0.2418 - val_loss: 3.7825 - val_accuracy: 0.2810\n",
            "Epoch 113/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7758 - accuracy: 0.2365\n",
            "Epoch 113: val_accuracy did not improve from 0.32381\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.7758 - accuracy: 0.2365 - val_loss: 3.7221 - val_accuracy: 0.2952\n",
            "Epoch 114/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7235 - accuracy: 0.2541\n",
            "Epoch 114: val_accuracy did not improve from 0.32381\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.7235 - accuracy: 0.2541 - val_loss: 3.7156 - val_accuracy: 0.3000\n",
            "Epoch 115/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7016 - accuracy: 0.2388\n",
            "Epoch 115: val_accuracy did not improve from 0.32381\n",
            "27/27 [==============================] - 11s 408ms/step - loss: 3.7016 - accuracy: 0.2388 - val_loss: 3.6759 - val_accuracy: 0.3000\n",
            "Epoch 116/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7117 - accuracy: 0.2500\n",
            "Epoch 116: val_accuracy improved from 0.32381 to 0.32857, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 25s 956ms/step - loss: 3.7117 - accuracy: 0.2500 - val_loss: 3.6462 - val_accuracy: 0.3286\n",
            "Epoch 117/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7111 - accuracy: 0.2629\n",
            "Epoch 117: val_accuracy did not improve from 0.32857\n",
            "27/27 [==============================] - 11s 406ms/step - loss: 3.7111 - accuracy: 0.2629 - val_loss: 3.7493 - val_accuracy: 0.2952\n",
            "Epoch 118/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7675 - accuracy: 0.2400\n",
            "Epoch 118: val_accuracy did not improve from 0.32857\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.7675 - accuracy: 0.2400 - val_loss: 3.7096 - val_accuracy: 0.3048\n",
            "Epoch 119/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7455 - accuracy: 0.2529\n",
            "Epoch 119: val_accuracy did not improve from 0.32857\n",
            "27/27 [==============================] - 11s 407ms/step - loss: 3.7455 - accuracy: 0.2529 - val_loss: 3.7174 - val_accuracy: 0.3238\n",
            "Epoch 120/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7166 - accuracy: 0.2535\n",
            "Epoch 120: val_accuracy did not improve from 0.32857\n",
            "27/27 [==============================] - 13s 466ms/step - loss: 3.7166 - accuracy: 0.2535 - val_loss: 3.6439 - val_accuracy: 0.3286\n",
            "Epoch 121/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7053 - accuracy: 0.2788\n",
            "Epoch 121: val_accuracy did not improve from 0.32857\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.7053 - accuracy: 0.2788 - val_loss: 3.8494 - val_accuracy: 0.2714\n",
            "Epoch 122/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7255 - accuracy: 0.2559\n",
            "Epoch 122: val_accuracy did not improve from 0.32857\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.7255 - accuracy: 0.2559 - val_loss: 3.7403 - val_accuracy: 0.2857\n",
            "Epoch 123/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7135 - accuracy: 0.2588\n",
            "Epoch 123: val_accuracy did not improve from 0.32857\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.7135 - accuracy: 0.2588 - val_loss: 3.7767 - val_accuracy: 0.3190\n",
            "Epoch 124/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6223 - accuracy: 0.2746\n",
            "Epoch 124: val_accuracy did not improve from 0.32857\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.6223 - accuracy: 0.2746 - val_loss: 3.7539 - val_accuracy: 0.3143\n",
            "Epoch 125/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6628 - accuracy: 0.2606\n",
            "Epoch 125: val_accuracy did not improve from 0.32857\n",
            "27/27 [==============================] - 11s 408ms/step - loss: 3.6628 - accuracy: 0.2606 - val_loss: 3.7310 - val_accuracy: 0.2952\n",
            "Epoch 126/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7016 - accuracy: 0.2676\n",
            "Epoch 126: val_accuracy did not improve from 0.32857\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.7016 - accuracy: 0.2676 - val_loss: 3.6922 - val_accuracy: 0.3143\n",
            "Epoch 127/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7196 - accuracy: 0.2617\n",
            "Epoch 127: val_accuracy did not improve from 0.32857\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.7196 - accuracy: 0.2617 - val_loss: 3.6948 - val_accuracy: 0.3048\n",
            "Epoch 128/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6973 - accuracy: 0.2664\n",
            "Epoch 128: val_accuracy did not improve from 0.32857\n",
            "27/27 [==============================] - 11s 407ms/step - loss: 3.6973 - accuracy: 0.2664 - val_loss: 3.6797 - val_accuracy: 0.2905\n",
            "Epoch 129/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6855 - accuracy: 0.2717\n",
            "Epoch 129: val_accuracy did not improve from 0.32857\n",
            "27/27 [==============================] - 11s 408ms/step - loss: 3.6855 - accuracy: 0.2717 - val_loss: 3.8006 - val_accuracy: 0.2524\n",
            "Epoch 130/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6888 - accuracy: 0.2688\n",
            "Epoch 130: val_accuracy did not improve from 0.32857\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.6888 - accuracy: 0.2688 - val_loss: 3.6775 - val_accuracy: 0.3000\n",
            "Epoch 131/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6906 - accuracy: 0.2635\n",
            "Epoch 131: val_accuracy did not improve from 0.32857\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.6906 - accuracy: 0.2635 - val_loss: 3.7123 - val_accuracy: 0.2952\n",
            "Epoch 132/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6565 - accuracy: 0.2735\n",
            "Epoch 132: val_accuracy did not improve from 0.32857\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.6565 - accuracy: 0.2735 - val_loss: 3.7555 - val_accuracy: 0.2810\n",
            "Epoch 133/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7163 - accuracy: 0.2553\n",
            "Epoch 133: val_accuracy did not improve from 0.32857\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.7163 - accuracy: 0.2553 - val_loss: 3.6799 - val_accuracy: 0.3048\n",
            "Epoch 134/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.7132 - accuracy: 0.2606\n",
            "Epoch 134: val_accuracy improved from 0.32857 to 0.33810, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 25s 956ms/step - loss: 3.7132 - accuracy: 0.2606 - val_loss: 3.6826 - val_accuracy: 0.3381\n",
            "Epoch 135/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6904 - accuracy: 0.2805\n",
            "Epoch 135: val_accuracy improved from 0.33810 to 0.35238, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 983ms/step - loss: 3.6904 - accuracy: 0.2805 - val_loss: 3.7109 - val_accuracy: 0.3524\n",
            "Epoch 136/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6879 - accuracy: 0.2799\n",
            "Epoch 136: val_accuracy did not improve from 0.35238\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.6879 - accuracy: 0.2799 - val_loss: 3.6602 - val_accuracy: 0.3238\n",
            "Epoch 137/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6607 - accuracy: 0.2705\n",
            "Epoch 137: val_accuracy did not improve from 0.35238\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.6607 - accuracy: 0.2705 - val_loss: 3.6539 - val_accuracy: 0.3476\n",
            "Epoch 138/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6271 - accuracy: 0.2700\n",
            "Epoch 138: val_accuracy did not improve from 0.35238\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.6271 - accuracy: 0.2700 - val_loss: 3.5975 - val_accuracy: 0.3190\n",
            "Epoch 139/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6617 - accuracy: 0.2782\n",
            "Epoch 139: val_accuracy did not improve from 0.35238\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.6617 - accuracy: 0.2782 - val_loss: 3.6442 - val_accuracy: 0.3095\n",
            "Epoch 140/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6201 - accuracy: 0.2723\n",
            "Epoch 140: val_accuracy did not improve from 0.35238\n",
            "27/27 [==============================] - 13s 465ms/step - loss: 3.6201 - accuracy: 0.2723 - val_loss: 3.6369 - val_accuracy: 0.3048\n",
            "Epoch 141/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6348 - accuracy: 0.2758\n",
            "Epoch 141: val_accuracy did not improve from 0.35238\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.6348 - accuracy: 0.2758 - val_loss: 3.5927 - val_accuracy: 0.3000\n",
            "Epoch 142/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6826 - accuracy: 0.2682\n",
            "Epoch 142: val_accuracy did not improve from 0.35238\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.6826 - accuracy: 0.2682 - val_loss: 3.5500 - val_accuracy: 0.3333\n",
            "Epoch 143/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6337 - accuracy: 0.2735\n",
            "Epoch 143: val_accuracy did not improve from 0.35238\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.6337 - accuracy: 0.2735 - val_loss: 3.6294 - val_accuracy: 0.3238\n",
            "Epoch 144/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6550 - accuracy: 0.2811\n",
            "Epoch 144: val_accuracy did not improve from 0.35238\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.6550 - accuracy: 0.2811 - val_loss: 3.5738 - val_accuracy: 0.3095\n",
            "Epoch 145/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5707 - accuracy: 0.2893\n",
            "Epoch 145: val_accuracy did not improve from 0.35238\n",
            "27/27 [==============================] - 11s 414ms/step - loss: 3.5707 - accuracy: 0.2893 - val_loss: 3.6467 - val_accuracy: 0.3238\n",
            "Epoch 146/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6493 - accuracy: 0.2729\n",
            "Epoch 146: val_accuracy did not improve from 0.35238\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.6493 - accuracy: 0.2729 - val_loss: 3.6463 - val_accuracy: 0.3286\n",
            "Epoch 147/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6316 - accuracy: 0.2805\n",
            "Epoch 147: val_accuracy did not improve from 0.35238\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.6316 - accuracy: 0.2805 - val_loss: 3.5614 - val_accuracy: 0.3238\n",
            "Epoch 148/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6239 - accuracy: 0.2764\n",
            "Epoch 148: val_accuracy did not improve from 0.35238\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.6239 - accuracy: 0.2764 - val_loss: 3.5747 - val_accuracy: 0.3333\n",
            "Epoch 149/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5815 - accuracy: 0.3093\n",
            "Epoch 149: val_accuracy did not improve from 0.35238\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.5815 - accuracy: 0.3093 - val_loss: 3.5859 - val_accuracy: 0.3381\n",
            "Epoch 150/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5718 - accuracy: 0.2917\n",
            "Epoch 150: val_accuracy did not improve from 0.35238\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.5718 - accuracy: 0.2917 - val_loss: 3.6903 - val_accuracy: 0.2952\n",
            "Epoch 151/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6661 - accuracy: 0.2711\n",
            "Epoch 151: val_accuracy did not improve from 0.35238\n",
            "27/27 [==============================] - 11s 424ms/step - loss: 3.6661 - accuracy: 0.2711 - val_loss: 3.5554 - val_accuracy: 0.3476\n",
            "Epoch 152/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6035 - accuracy: 0.2928\n",
            "Epoch 152: val_accuracy did not improve from 0.35238\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.6035 - accuracy: 0.2928 - val_loss: 3.5645 - val_accuracy: 0.3429\n",
            "Epoch 153/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6270 - accuracy: 0.2840\n",
            "Epoch 153: val_accuracy did not improve from 0.35238\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.6270 - accuracy: 0.2840 - val_loss: 3.5935 - val_accuracy: 0.3190\n",
            "Epoch 154/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6394 - accuracy: 0.2788\n",
            "Epoch 154: val_accuracy improved from 0.35238 to 0.36190, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 25s 955ms/step - loss: 3.6394 - accuracy: 0.2788 - val_loss: 3.5714 - val_accuracy: 0.3619\n",
            "Epoch 155/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6284 - accuracy: 0.2887\n",
            "Epoch 155: val_accuracy did not improve from 0.36190\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.6284 - accuracy: 0.2887 - val_loss: 3.6518 - val_accuracy: 0.3048\n",
            "Epoch 156/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6550 - accuracy: 0.2958\n",
            "Epoch 156: val_accuracy did not improve from 0.36190\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.6550 - accuracy: 0.2958 - val_loss: 3.5914 - val_accuracy: 0.3286\n",
            "Epoch 157/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6154 - accuracy: 0.3081\n",
            "Epoch 157: val_accuracy improved from 0.36190 to 0.38095, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 25s 960ms/step - loss: 3.6154 - accuracy: 0.3081 - val_loss: 3.5057 - val_accuracy: 0.3810\n",
            "Epoch 158/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6020 - accuracy: 0.2987\n",
            "Epoch 158: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.6020 - accuracy: 0.2987 - val_loss: 3.5521 - val_accuracy: 0.3429\n",
            "Epoch 159/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5897 - accuracy: 0.3028\n",
            "Epoch 159: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 407ms/step - loss: 3.5897 - accuracy: 0.3028 - val_loss: 3.5567 - val_accuracy: 0.3476\n",
            "Epoch 160/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6245 - accuracy: 0.2917\n",
            "Epoch 160: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.6245 - accuracy: 0.2917 - val_loss: 3.6163 - val_accuracy: 0.3143\n",
            "Epoch 161/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5920 - accuracy: 0.2964\n",
            "Epoch 161: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 12s 451ms/step - loss: 3.5920 - accuracy: 0.2964 - val_loss: 3.5060 - val_accuracy: 0.3571\n",
            "Epoch 162/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5546 - accuracy: 0.3151\n",
            "Epoch 162: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.5546 - accuracy: 0.3151 - val_loss: 3.6282 - val_accuracy: 0.3333\n",
            "Epoch 163/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5998 - accuracy: 0.2981\n",
            "Epoch 163: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.5998 - accuracy: 0.2981 - val_loss: 3.5655 - val_accuracy: 0.3524\n",
            "Epoch 164/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6283 - accuracy: 0.3011\n",
            "Epoch 164: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.6283 - accuracy: 0.3011 - val_loss: 3.6278 - val_accuracy: 0.3714\n",
            "Epoch 165/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6407 - accuracy: 0.2946\n",
            "Epoch 165: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.6407 - accuracy: 0.2946 - val_loss: 3.5350 - val_accuracy: 0.3381\n",
            "Epoch 166/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5958 - accuracy: 0.3040\n",
            "Epoch 166: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.5958 - accuracy: 0.3040 - val_loss: 3.6181 - val_accuracy: 0.3048\n",
            "Epoch 167/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6252 - accuracy: 0.2928\n",
            "Epoch 167: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.6252 - accuracy: 0.2928 - val_loss: 3.6097 - val_accuracy: 0.3095\n",
            "Epoch 168/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6538 - accuracy: 0.2852\n",
            "Epoch 168: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.6538 - accuracy: 0.2852 - val_loss: 3.5550 - val_accuracy: 0.3333\n",
            "Epoch 169/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6249 - accuracy: 0.2964\n",
            "Epoch 169: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.6249 - accuracy: 0.2964 - val_loss: 3.4759 - val_accuracy: 0.3667\n",
            "Epoch 170/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5576 - accuracy: 0.3099\n",
            "Epoch 170: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.5576 - accuracy: 0.3099 - val_loss: 3.5324 - val_accuracy: 0.3619\n",
            "Epoch 171/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5583 - accuracy: 0.3192\n",
            "Epoch 171: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.5583 - accuracy: 0.3192 - val_loss: 3.5312 - val_accuracy: 0.3381\n",
            "Epoch 172/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5497 - accuracy: 0.3075\n",
            "Epoch 172: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.5497 - accuracy: 0.3075 - val_loss: 3.5815 - val_accuracy: 0.3333\n",
            "Epoch 173/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5607 - accuracy: 0.3087\n",
            "Epoch 173: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 414ms/step - loss: 3.5607 - accuracy: 0.3087 - val_loss: 3.4904 - val_accuracy: 0.3476\n",
            "Epoch 174/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5080 - accuracy: 0.3292\n",
            "Epoch 174: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 414ms/step - loss: 3.5080 - accuracy: 0.3292 - val_loss: 3.6079 - val_accuracy: 0.3143\n",
            "Epoch 175/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5744 - accuracy: 0.2940\n",
            "Epoch 175: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.5744 - accuracy: 0.2940 - val_loss: 3.4481 - val_accuracy: 0.3476\n",
            "Epoch 176/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5939 - accuracy: 0.3087\n",
            "Epoch 176: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 407ms/step - loss: 3.5939 - accuracy: 0.3087 - val_loss: 3.5462 - val_accuracy: 0.3762\n",
            "Epoch 177/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6402 - accuracy: 0.3081\n",
            "Epoch 177: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.6402 - accuracy: 0.3081 - val_loss: 3.5592 - val_accuracy: 0.3714\n",
            "Epoch 178/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5618 - accuracy: 0.3146\n",
            "Epoch 178: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.5618 - accuracy: 0.3146 - val_loss: 3.5730 - val_accuracy: 0.3762\n",
            "Epoch 179/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5654 - accuracy: 0.3063\n",
            "Epoch 179: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.5654 - accuracy: 0.3063 - val_loss: 3.5629 - val_accuracy: 0.3714\n",
            "Epoch 180/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6102 - accuracy: 0.2887\n",
            "Epoch 180: val_accuracy did not improve from 0.38095\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.6102 - accuracy: 0.2887 - val_loss: 3.5561 - val_accuracy: 0.3238\n",
            "Epoch 181/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5050 - accuracy: 0.3386\n",
            "Epoch 181: val_accuracy improved from 0.38095 to 0.38571, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 975ms/step - loss: 3.5050 - accuracy: 0.3386 - val_loss: 3.4992 - val_accuracy: 0.3857\n",
            "Epoch 182/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5395 - accuracy: 0.3128\n",
            "Epoch 182: val_accuracy did not improve from 0.38571\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.5395 - accuracy: 0.3128 - val_loss: 3.5387 - val_accuracy: 0.3476\n",
            "Epoch 183/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6325 - accuracy: 0.3187\n",
            "Epoch 183: val_accuracy did not improve from 0.38571\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.6325 - accuracy: 0.3187 - val_loss: 3.6264 - val_accuracy: 0.3429\n",
            "Epoch 184/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6061 - accuracy: 0.3110\n",
            "Epoch 184: val_accuracy improved from 0.38571 to 0.39048, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 974ms/step - loss: 3.6061 - accuracy: 0.3110 - val_loss: 3.4737 - val_accuracy: 0.3905\n",
            "Epoch 185/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5929 - accuracy: 0.2964\n",
            "Epoch 185: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.5929 - accuracy: 0.2964 - val_loss: 3.5177 - val_accuracy: 0.3667\n",
            "Epoch 186/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5264 - accuracy: 0.3263\n",
            "Epoch 186: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.5264 - accuracy: 0.3263 - val_loss: 3.5201 - val_accuracy: 0.3524\n",
            "Epoch 187/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5407 - accuracy: 0.3298\n",
            "Epoch 187: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.5407 - accuracy: 0.3298 - val_loss: 3.6239 - val_accuracy: 0.3619\n",
            "Epoch 188/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5506 - accuracy: 0.3292\n",
            "Epoch 188: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.5506 - accuracy: 0.3292 - val_loss: 3.5779 - val_accuracy: 0.3476\n",
            "Epoch 189/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5730 - accuracy: 0.3263\n",
            "Epoch 189: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.5730 - accuracy: 0.3263 - val_loss: 3.4983 - val_accuracy: 0.3667\n",
            "Epoch 190/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5888 - accuracy: 0.3257\n",
            "Epoch 190: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 414ms/step - loss: 3.5888 - accuracy: 0.3257 - val_loss: 3.6329 - val_accuracy: 0.3667\n",
            "Epoch 191/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6129 - accuracy: 0.3110\n",
            "Epoch 191: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.6129 - accuracy: 0.3110 - val_loss: 3.5521 - val_accuracy: 0.3619\n",
            "Epoch 192/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5861 - accuracy: 0.3351\n",
            "Epoch 192: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 419ms/step - loss: 3.5861 - accuracy: 0.3351 - val_loss: 3.5645 - val_accuracy: 0.3619\n",
            "Epoch 193/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5661 - accuracy: 0.3316\n",
            "Epoch 193: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.5661 - accuracy: 0.3316 - val_loss: 3.5560 - val_accuracy: 0.3714\n",
            "Epoch 194/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5596 - accuracy: 0.3228\n",
            "Epoch 194: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.5596 - accuracy: 0.3228 - val_loss: 3.5936 - val_accuracy: 0.3857\n",
            "Epoch 195/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.6586 - accuracy: 0.3052\n",
            "Epoch 195: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.6586 - accuracy: 0.3052 - val_loss: 3.5755 - val_accuracy: 0.3476\n",
            "Epoch 196/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5811 - accuracy: 0.3122\n",
            "Epoch 196: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.5811 - accuracy: 0.3122 - val_loss: 3.5051 - val_accuracy: 0.3810\n",
            "Epoch 197/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4989 - accuracy: 0.3245\n",
            "Epoch 197: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.4989 - accuracy: 0.3245 - val_loss: 3.5154 - val_accuracy: 0.3619\n",
            "Epoch 198/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5888 - accuracy: 0.3104\n",
            "Epoch 198: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.5888 - accuracy: 0.3104 - val_loss: 3.6050 - val_accuracy: 0.3190\n",
            "Epoch 199/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5403 - accuracy: 0.3286\n",
            "Epoch 199: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.5403 - accuracy: 0.3286 - val_loss: 3.5383 - val_accuracy: 0.3524\n",
            "Epoch 200/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5317 - accuracy: 0.3181\n",
            "Epoch 200: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.5317 - accuracy: 0.3181 - val_loss: 3.5232 - val_accuracy: 0.3762\n",
            "Epoch 201/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5346 - accuracy: 0.3333\n",
            "Epoch 201: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 13s 472ms/step - loss: 3.5346 - accuracy: 0.3333 - val_loss: 3.4294 - val_accuracy: 0.3810\n",
            "Epoch 202/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5835 - accuracy: 0.3263\n",
            "Epoch 202: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.5835 - accuracy: 0.3263 - val_loss: 3.4708 - val_accuracy: 0.3810\n",
            "Epoch 203/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5552 - accuracy: 0.3269\n",
            "Epoch 203: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.5552 - accuracy: 0.3269 - val_loss: 3.5329 - val_accuracy: 0.3810\n",
            "Epoch 204/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5447 - accuracy: 0.3286\n",
            "Epoch 204: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 408ms/step - loss: 3.5447 - accuracy: 0.3286 - val_loss: 3.4677 - val_accuracy: 0.3762\n",
            "Epoch 205/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5621 - accuracy: 0.3333\n",
            "Epoch 205: val_accuracy did not improve from 0.39048\n",
            "27/27 [==============================] - 11s 414ms/step - loss: 3.5621 - accuracy: 0.3333 - val_loss: 3.6181 - val_accuracy: 0.3333\n",
            "Epoch 206/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5808 - accuracy: 0.3327\n",
            "Epoch 206: val_accuracy improved from 0.39048 to 0.40000, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 991ms/step - loss: 3.5808 - accuracy: 0.3327 - val_loss: 3.4898 - val_accuracy: 0.4000\n",
            "Epoch 207/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5817 - accuracy: 0.3269\n",
            "Epoch 207: val_accuracy did not improve from 0.40000\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.5817 - accuracy: 0.3269 - val_loss: 3.5635 - val_accuracy: 0.3952\n",
            "Epoch 208/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5765 - accuracy: 0.3415\n",
            "Epoch 208: val_accuracy improved from 0.40000 to 0.40952, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 25s 961ms/step - loss: 3.5765 - accuracy: 0.3415 - val_loss: 3.5827 - val_accuracy: 0.4095\n",
            "Epoch 209/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5632 - accuracy: 0.3369\n",
            "Epoch 209: val_accuracy did not improve from 0.40952\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.5632 - accuracy: 0.3369 - val_loss: 3.5199 - val_accuracy: 0.3714\n",
            "Epoch 210/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5425 - accuracy: 0.3327\n",
            "Epoch 210: val_accuracy did not improve from 0.40952\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.5425 - accuracy: 0.3327 - val_loss: 3.4370 - val_accuracy: 0.3762\n",
            "Epoch 211/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5368 - accuracy: 0.3316\n",
            "Epoch 211: val_accuracy did not improve from 0.40952\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.5368 - accuracy: 0.3316 - val_loss: 3.5098 - val_accuracy: 0.3667\n",
            "Epoch 212/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5260 - accuracy: 0.3292\n",
            "Epoch 212: val_accuracy did not improve from 0.40952\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.5260 - accuracy: 0.3292 - val_loss: 3.4316 - val_accuracy: 0.4000\n",
            "Epoch 213/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5778 - accuracy: 0.3275\n",
            "Epoch 213: val_accuracy did not improve from 0.40952\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.5778 - accuracy: 0.3275 - val_loss: 3.4618 - val_accuracy: 0.3857\n",
            "Epoch 214/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4972 - accuracy: 0.3498\n",
            "Epoch 214: val_accuracy improved from 0.40952 to 0.41429, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 992ms/step - loss: 3.4972 - accuracy: 0.3498 - val_loss: 3.4063 - val_accuracy: 0.4143\n",
            "Epoch 215/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4857 - accuracy: 0.3492\n",
            "Epoch 215: val_accuracy did not improve from 0.41429\n",
            "27/27 [==============================] - 12s 424ms/step - loss: 3.4857 - accuracy: 0.3492 - val_loss: 3.4064 - val_accuracy: 0.4143\n",
            "Epoch 216/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5967 - accuracy: 0.3345\n",
            "Epoch 216: val_accuracy did not improve from 0.41429\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.5967 - accuracy: 0.3345 - val_loss: 3.5409 - val_accuracy: 0.3762\n",
            "Epoch 217/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5580 - accuracy: 0.3351\n",
            "Epoch 217: val_accuracy did not improve from 0.41429\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.5580 - accuracy: 0.3351 - val_loss: 3.4456 - val_accuracy: 0.4000\n",
            "Epoch 218/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5291 - accuracy: 0.3462\n",
            "Epoch 218: val_accuracy did not improve from 0.41429\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.5291 - accuracy: 0.3462 - val_loss: 3.4440 - val_accuracy: 0.4048\n",
            "Epoch 219/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5618 - accuracy: 0.3357\n",
            "Epoch 219: val_accuracy improved from 0.41429 to 0.43333, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 984ms/step - loss: 3.5618 - accuracy: 0.3357 - val_loss: 3.4757 - val_accuracy: 0.4333\n",
            "Epoch 220/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5931 - accuracy: 0.3245\n",
            "Epoch 220: val_accuracy did not improve from 0.43333\n",
            "27/27 [==============================] - 11s 414ms/step - loss: 3.5931 - accuracy: 0.3245 - val_loss: 3.3979 - val_accuracy: 0.4000\n",
            "Epoch 221/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5128 - accuracy: 0.3363\n",
            "Epoch 221: val_accuracy did not improve from 0.43333\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.5128 - accuracy: 0.3363 - val_loss: 3.3646 - val_accuracy: 0.4000\n",
            "Epoch 222/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4942 - accuracy: 0.3562\n",
            "Epoch 222: val_accuracy did not improve from 0.43333\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.4942 - accuracy: 0.3562 - val_loss: 3.4731 - val_accuracy: 0.3571\n",
            "Epoch 223/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5424 - accuracy: 0.3545\n",
            "Epoch 223: val_accuracy did not improve from 0.43333\n",
            "27/27 [==============================] - 11s 419ms/step - loss: 3.5424 - accuracy: 0.3545 - val_loss: 3.4389 - val_accuracy: 0.3524\n",
            "Epoch 224/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5030 - accuracy: 0.3404\n",
            "Epoch 224: val_accuracy did not improve from 0.43333\n",
            "27/27 [==============================] - 11s 422ms/step - loss: 3.5030 - accuracy: 0.3404 - val_loss: 3.4281 - val_accuracy: 0.4286\n",
            "Epoch 225/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5059 - accuracy: 0.3509\n",
            "Epoch 225: val_accuracy did not improve from 0.43333\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.5059 - accuracy: 0.3509 - val_loss: 3.4330 - val_accuracy: 0.4095\n",
            "Epoch 226/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5375 - accuracy: 0.3363\n",
            "Epoch 226: val_accuracy did not improve from 0.43333\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.5375 - accuracy: 0.3363 - val_loss: 3.4656 - val_accuracy: 0.3714\n",
            "Epoch 227/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5682 - accuracy: 0.3468\n",
            "Epoch 227: val_accuracy improved from 0.43333 to 0.43810, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 971ms/step - loss: 3.5682 - accuracy: 0.3468 - val_loss: 3.4627 - val_accuracy: 0.4381\n",
            "Epoch 228/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5454 - accuracy: 0.3351\n",
            "Epoch 228: val_accuracy did not improve from 0.43810\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.5454 - accuracy: 0.3351 - val_loss: 3.4515 - val_accuracy: 0.4333\n",
            "Epoch 229/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5604 - accuracy: 0.3504\n",
            "Epoch 229: val_accuracy did not improve from 0.43810\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.5604 - accuracy: 0.3504 - val_loss: 3.4069 - val_accuracy: 0.4333\n",
            "Epoch 230/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5913 - accuracy: 0.3345\n",
            "Epoch 230: val_accuracy did not improve from 0.43810\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.5913 - accuracy: 0.3345 - val_loss: 3.5344 - val_accuracy: 0.3905\n",
            "Epoch 231/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5629 - accuracy: 0.3451\n",
            "Epoch 231: val_accuracy did not improve from 0.43810\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.5629 - accuracy: 0.3451 - val_loss: 3.4795 - val_accuracy: 0.3905\n",
            "Epoch 232/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5835 - accuracy: 0.3468\n",
            "Epoch 232: val_accuracy did not improve from 0.43810\n",
            "27/27 [==============================] - 11s 422ms/step - loss: 3.5835 - accuracy: 0.3468 - val_loss: 3.4432 - val_accuracy: 0.3952\n",
            "Epoch 233/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5728 - accuracy: 0.3380\n",
            "Epoch 233: val_accuracy did not improve from 0.43810\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.5728 - accuracy: 0.3380 - val_loss: 3.4800 - val_accuracy: 0.3952\n",
            "Epoch 234/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5686 - accuracy: 0.3404\n",
            "Epoch 234: val_accuracy did not improve from 0.43810\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.5686 - accuracy: 0.3404 - val_loss: 3.5235 - val_accuracy: 0.3667\n",
            "Epoch 235/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5379 - accuracy: 0.3680\n",
            "Epoch 235: val_accuracy did not improve from 0.43810\n",
            "27/27 [==============================] - 11s 426ms/step - loss: 3.5379 - accuracy: 0.3680 - val_loss: 3.4107 - val_accuracy: 0.4333\n",
            "Epoch 236/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5194 - accuracy: 0.3674\n",
            "Epoch 236: val_accuracy improved from 0.43810 to 0.45238, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 973ms/step - loss: 3.5194 - accuracy: 0.3674 - val_loss: 3.4025 - val_accuracy: 0.4524\n",
            "Epoch 237/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4782 - accuracy: 0.3756\n",
            "Epoch 237: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.4782 - accuracy: 0.3756 - val_loss: 3.4326 - val_accuracy: 0.4190\n",
            "Epoch 238/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5440 - accuracy: 0.3562\n",
            "Epoch 238: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 419ms/step - loss: 3.5440 - accuracy: 0.3562 - val_loss: 3.4526 - val_accuracy: 0.4095\n",
            "Epoch 239/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5416 - accuracy: 0.3486\n",
            "Epoch 239: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 13s 471ms/step - loss: 3.5416 - accuracy: 0.3486 - val_loss: 3.3592 - val_accuracy: 0.4429\n",
            "Epoch 240/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4740 - accuracy: 0.3533\n",
            "Epoch 240: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.4740 - accuracy: 0.3533 - val_loss: 3.3622 - val_accuracy: 0.4333\n",
            "Epoch 241/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5001 - accuracy: 0.3504\n",
            "Epoch 241: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.5001 - accuracy: 0.3504 - val_loss: 3.4423 - val_accuracy: 0.4048\n",
            "Epoch 242/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5171 - accuracy: 0.3445\n",
            "Epoch 242: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.5171 - accuracy: 0.3445 - val_loss: 3.4085 - val_accuracy: 0.4381\n",
            "Epoch 243/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5482 - accuracy: 0.3433\n",
            "Epoch 243: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.5482 - accuracy: 0.3433 - val_loss: 3.4495 - val_accuracy: 0.4048\n",
            "Epoch 244/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4785 - accuracy: 0.3574\n",
            "Epoch 244: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.4785 - accuracy: 0.3574 - val_loss: 3.4796 - val_accuracy: 0.3667\n",
            "Epoch 245/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4726 - accuracy: 0.3662\n",
            "Epoch 245: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.4726 - accuracy: 0.3662 - val_loss: 3.4413 - val_accuracy: 0.4238\n",
            "Epoch 246/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4918 - accuracy: 0.3691\n",
            "Epoch 246: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.4918 - accuracy: 0.3691 - val_loss: 3.4028 - val_accuracy: 0.4095\n",
            "Epoch 247/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5417 - accuracy: 0.3492\n",
            "Epoch 247: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 414ms/step - loss: 3.5417 - accuracy: 0.3492 - val_loss: 3.4800 - val_accuracy: 0.4048\n",
            "Epoch 248/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5392 - accuracy: 0.3451\n",
            "Epoch 248: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.5392 - accuracy: 0.3451 - val_loss: 3.4528 - val_accuracy: 0.3952\n",
            "Epoch 249/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5013 - accuracy: 0.3680\n",
            "Epoch 249: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.5013 - accuracy: 0.3680 - val_loss: 3.4232 - val_accuracy: 0.4048\n",
            "Epoch 250/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5058 - accuracy: 0.3621\n",
            "Epoch 250: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.5058 - accuracy: 0.3621 - val_loss: 3.4685 - val_accuracy: 0.3810\n",
            "Epoch 251/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4829 - accuracy: 0.3773\n",
            "Epoch 251: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 414ms/step - loss: 3.4829 - accuracy: 0.3773 - val_loss: 3.4729 - val_accuracy: 0.4000\n",
            "Epoch 252/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5479 - accuracy: 0.3609\n",
            "Epoch 252: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.5479 - accuracy: 0.3609 - val_loss: 3.4766 - val_accuracy: 0.4238\n",
            "Epoch 253/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5248 - accuracy: 0.3674\n",
            "Epoch 253: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.5248 - accuracy: 0.3674 - val_loss: 3.5784 - val_accuracy: 0.3810\n",
            "Epoch 254/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4837 - accuracy: 0.3756\n",
            "Epoch 254: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.4837 - accuracy: 0.3756 - val_loss: 3.4923 - val_accuracy: 0.4190\n",
            "Epoch 255/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4901 - accuracy: 0.3773\n",
            "Epoch 255: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 414ms/step - loss: 3.4901 - accuracy: 0.3773 - val_loss: 3.4029 - val_accuracy: 0.4429\n",
            "Epoch 256/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5275 - accuracy: 0.3550\n",
            "Epoch 256: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.5275 - accuracy: 0.3550 - val_loss: 3.5527 - val_accuracy: 0.3714\n",
            "Epoch 257/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4504 - accuracy: 0.3680\n",
            "Epoch 257: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.4504 - accuracy: 0.3680 - val_loss: 3.4873 - val_accuracy: 0.3810\n",
            "Epoch 258/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4873 - accuracy: 0.3750\n",
            "Epoch 258: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.4873 - accuracy: 0.3750 - val_loss: 3.4642 - val_accuracy: 0.4286\n",
            "Epoch 259/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5328 - accuracy: 0.3633\n",
            "Epoch 259: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.5328 - accuracy: 0.3633 - val_loss: 3.3642 - val_accuracy: 0.4429\n",
            "Epoch 260/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5172 - accuracy: 0.3644\n",
            "Epoch 260: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.5172 - accuracy: 0.3644 - val_loss: 3.4676 - val_accuracy: 0.4000\n",
            "Epoch 261/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4904 - accuracy: 0.3715\n",
            "Epoch 261: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 414ms/step - loss: 3.4904 - accuracy: 0.3715 - val_loss: 3.4450 - val_accuracy: 0.4476\n",
            "Epoch 262/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4918 - accuracy: 0.3691\n",
            "Epoch 262: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 12s 446ms/step - loss: 3.4918 - accuracy: 0.3691 - val_loss: 3.5427 - val_accuracy: 0.4286\n",
            "Epoch 263/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4911 - accuracy: 0.3820\n",
            "Epoch 263: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.4911 - accuracy: 0.3820 - val_loss: 3.4863 - val_accuracy: 0.4095\n",
            "Epoch 264/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5255 - accuracy: 0.3826\n",
            "Epoch 264: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.5255 - accuracy: 0.3826 - val_loss: 3.5090 - val_accuracy: 0.4143\n",
            "Epoch 265/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5237 - accuracy: 0.3574\n",
            "Epoch 265: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 414ms/step - loss: 3.5237 - accuracy: 0.3574 - val_loss: 3.4904 - val_accuracy: 0.3952\n",
            "Epoch 266/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4974 - accuracy: 0.3815\n",
            "Epoch 266: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.4974 - accuracy: 0.3815 - val_loss: 3.5104 - val_accuracy: 0.4000\n",
            "Epoch 267/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5628 - accuracy: 0.3480\n",
            "Epoch 267: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.5628 - accuracy: 0.3480 - val_loss: 3.4487 - val_accuracy: 0.4238\n",
            "Epoch 268/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5240 - accuracy: 0.3844\n",
            "Epoch 268: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.5240 - accuracy: 0.3844 - val_loss: 3.5153 - val_accuracy: 0.3714\n",
            "Epoch 269/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5537 - accuracy: 0.3703\n",
            "Epoch 269: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.5537 - accuracy: 0.3703 - val_loss: 3.5718 - val_accuracy: 0.3667\n",
            "Epoch 270/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5080 - accuracy: 0.3662\n",
            "Epoch 270: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 419ms/step - loss: 3.5080 - accuracy: 0.3662 - val_loss: 3.4943 - val_accuracy: 0.4000\n",
            "Epoch 271/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5255 - accuracy: 0.3744\n",
            "Epoch 271: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.5255 - accuracy: 0.3744 - val_loss: 3.4900 - val_accuracy: 0.3714\n",
            "Epoch 272/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5202 - accuracy: 0.3668\n",
            "Epoch 272: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.5202 - accuracy: 0.3668 - val_loss: 3.4901 - val_accuracy: 0.4000\n",
            "Epoch 273/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4961 - accuracy: 0.3674\n",
            "Epoch 273: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.4961 - accuracy: 0.3674 - val_loss: 3.5231 - val_accuracy: 0.3714\n",
            "Epoch 274/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4933 - accuracy: 0.3727\n",
            "Epoch 274: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.4933 - accuracy: 0.3727 - val_loss: 3.5516 - val_accuracy: 0.3857\n",
            "Epoch 275/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5272 - accuracy: 0.3633\n",
            "Epoch 275: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.5272 - accuracy: 0.3633 - val_loss: 3.4930 - val_accuracy: 0.4381\n",
            "Epoch 276/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5344 - accuracy: 0.3803\n",
            "Epoch 276: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.5344 - accuracy: 0.3803 - val_loss: 3.5065 - val_accuracy: 0.3857\n",
            "Epoch 277/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4949 - accuracy: 0.3862\n",
            "Epoch 277: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 409ms/step - loss: 3.4949 - accuracy: 0.3862 - val_loss: 3.6453 - val_accuracy: 0.3810\n",
            "Epoch 278/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5091 - accuracy: 0.3732\n",
            "Epoch 278: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.5091 - accuracy: 0.3732 - val_loss: 3.5236 - val_accuracy: 0.3810\n",
            "Epoch 279/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4810 - accuracy: 0.3932\n",
            "Epoch 279: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.4810 - accuracy: 0.3932 - val_loss: 3.3992 - val_accuracy: 0.4429\n",
            "Epoch 280/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4795 - accuracy: 0.3721\n",
            "Epoch 280: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 12s 446ms/step - loss: 3.4795 - accuracy: 0.3721 - val_loss: 3.4755 - val_accuracy: 0.4143\n",
            "Epoch 281/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4681 - accuracy: 0.3820\n",
            "Epoch 281: val_accuracy did not improve from 0.45238\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.4681 - accuracy: 0.3820 - val_loss: 3.4377 - val_accuracy: 0.4143\n",
            "Epoch 282/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4419 - accuracy: 0.3862\n",
            "Epoch 282: val_accuracy improved from 0.45238 to 0.46190, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 982ms/step - loss: 3.4419 - accuracy: 0.3862 - val_loss: 3.4092 - val_accuracy: 0.4619\n",
            "Epoch 283/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4384 - accuracy: 0.3938\n",
            "Epoch 283: val_accuracy did not improve from 0.46190\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.4384 - accuracy: 0.3938 - val_loss: 3.4306 - val_accuracy: 0.4190\n",
            "Epoch 284/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5286 - accuracy: 0.3662\n",
            "Epoch 284: val_accuracy did not improve from 0.46190\n",
            "27/27 [==============================] - 11s 423ms/step - loss: 3.5286 - accuracy: 0.3662 - val_loss: 3.4044 - val_accuracy: 0.4238\n",
            "Epoch 285/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4911 - accuracy: 0.3727\n",
            "Epoch 285: val_accuracy did not improve from 0.46190\n",
            "27/27 [==============================] - 11s 427ms/step - loss: 3.4911 - accuracy: 0.3727 - val_loss: 3.4279 - val_accuracy: 0.4190\n",
            "Epoch 286/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4519 - accuracy: 0.3826\n",
            "Epoch 286: val_accuracy did not improve from 0.46190\n",
            "27/27 [==============================] - 11s 414ms/step - loss: 3.4519 - accuracy: 0.3826 - val_loss: 3.4070 - val_accuracy: 0.4095\n",
            "Epoch 287/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4650 - accuracy: 0.3703\n",
            "Epoch 287: val_accuracy did not improve from 0.46190\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.4650 - accuracy: 0.3703 - val_loss: 3.4170 - val_accuracy: 0.4238\n",
            "Epoch 288/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4701 - accuracy: 0.3903\n",
            "Epoch 288: val_accuracy improved from 0.46190 to 0.49524, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 966ms/step - loss: 3.4701 - accuracy: 0.3903 - val_loss: 3.4010 - val_accuracy: 0.4952\n",
            "Epoch 289/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5115 - accuracy: 0.3926\n",
            "Epoch 289: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.5115 - accuracy: 0.3926 - val_loss: 3.4510 - val_accuracy: 0.4810\n",
            "Epoch 290/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5524 - accuracy: 0.3738\n",
            "Epoch 290: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.5524 - accuracy: 0.3738 - val_loss: 3.5148 - val_accuracy: 0.4429\n",
            "Epoch 291/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5454 - accuracy: 0.3879\n",
            "Epoch 291: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.5454 - accuracy: 0.3879 - val_loss: 3.4813 - val_accuracy: 0.4333\n",
            "Epoch 292/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4661 - accuracy: 0.3920\n",
            "Epoch 292: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.4661 - accuracy: 0.3920 - val_loss: 3.5349 - val_accuracy: 0.4143\n",
            "Epoch 293/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4975 - accuracy: 0.3768\n",
            "Epoch 293: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.4975 - accuracy: 0.3768 - val_loss: 3.4474 - val_accuracy: 0.4571\n",
            "Epoch 294/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5027 - accuracy: 0.3903\n",
            "Epoch 294: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.5027 - accuracy: 0.3903 - val_loss: 3.4295 - val_accuracy: 0.4571\n",
            "Epoch 295/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4601 - accuracy: 0.3961\n",
            "Epoch 295: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.4601 - accuracy: 0.3961 - val_loss: 3.4067 - val_accuracy: 0.4571\n",
            "Epoch 296/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5452 - accuracy: 0.3756\n",
            "Epoch 296: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 414ms/step - loss: 3.5452 - accuracy: 0.3756 - val_loss: 3.4914 - val_accuracy: 0.4333\n",
            "Epoch 297/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5224 - accuracy: 0.3856\n",
            "Epoch 297: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.5224 - accuracy: 0.3856 - val_loss: 3.4663 - val_accuracy: 0.4381\n",
            "Epoch 298/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5268 - accuracy: 0.3738\n",
            "Epoch 298: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.5268 - accuracy: 0.3738 - val_loss: 3.3923 - val_accuracy: 0.4476\n",
            "Epoch 299/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4379 - accuracy: 0.3897\n",
            "Epoch 299: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.4379 - accuracy: 0.3897 - val_loss: 3.3178 - val_accuracy: 0.4667\n",
            "Epoch 300/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4612 - accuracy: 0.3867\n",
            "Epoch 300: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.4612 - accuracy: 0.3867 - val_loss: 3.3918 - val_accuracy: 0.4857\n",
            "Epoch 301/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4949 - accuracy: 0.4014\n",
            "Epoch 301: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.4949 - accuracy: 0.4014 - val_loss: 3.4015 - val_accuracy: 0.4524\n",
            "Epoch 302/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5232 - accuracy: 0.3908\n",
            "Epoch 302: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.5232 - accuracy: 0.3908 - val_loss: 3.5014 - val_accuracy: 0.4333\n",
            "Epoch 303/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5719 - accuracy: 0.3879\n",
            "Epoch 303: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 410ms/step - loss: 3.5719 - accuracy: 0.3879 - val_loss: 3.4386 - val_accuracy: 0.4524\n",
            "Epoch 304/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5444 - accuracy: 0.3732\n",
            "Epoch 304: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 419ms/step - loss: 3.5444 - accuracy: 0.3732 - val_loss: 3.4271 - val_accuracy: 0.4429\n",
            "Epoch 305/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4283 - accuracy: 0.3996\n",
            "Epoch 305: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 12s 424ms/step - loss: 3.4283 - accuracy: 0.3996 - val_loss: 3.4578 - val_accuracy: 0.4238\n",
            "Epoch 306/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5041 - accuracy: 0.3773\n",
            "Epoch 306: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.5041 - accuracy: 0.3773 - val_loss: 3.4961 - val_accuracy: 0.4476\n",
            "Epoch 307/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4732 - accuracy: 0.3908\n",
            "Epoch 307: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.4732 - accuracy: 0.3908 - val_loss: 3.4725 - val_accuracy: 0.4333\n",
            "Epoch 308/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4203 - accuracy: 0.3920\n",
            "Epoch 308: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.4203 - accuracy: 0.3920 - val_loss: 3.3885 - val_accuracy: 0.4190\n",
            "Epoch 309/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4641 - accuracy: 0.3914\n",
            "Epoch 309: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.4641 - accuracy: 0.3914 - val_loss: 3.5765 - val_accuracy: 0.4238\n",
            "Epoch 310/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4544 - accuracy: 0.4079\n",
            "Epoch 310: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.4544 - accuracy: 0.4079 - val_loss: 3.4823 - val_accuracy: 0.4286\n",
            "Epoch 311/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4719 - accuracy: 0.3891\n",
            "Epoch 311: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.4719 - accuracy: 0.3891 - val_loss: 3.5338 - val_accuracy: 0.4381\n",
            "Epoch 312/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4730 - accuracy: 0.3955\n",
            "Epoch 312: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.4730 - accuracy: 0.3955 - val_loss: 3.4275 - val_accuracy: 0.4333\n",
            "Epoch 313/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4868 - accuracy: 0.3991\n",
            "Epoch 313: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 419ms/step - loss: 3.4868 - accuracy: 0.3991 - val_loss: 3.4545 - val_accuracy: 0.4524\n",
            "Epoch 314/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5084 - accuracy: 0.3826\n",
            "Epoch 314: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.5084 - accuracy: 0.3826 - val_loss: 3.4752 - val_accuracy: 0.4381\n",
            "Epoch 315/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4982 - accuracy: 0.4061\n",
            "Epoch 315: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 12s 451ms/step - loss: 3.4982 - accuracy: 0.4061 - val_loss: 3.5873 - val_accuracy: 0.4095\n",
            "Epoch 316/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4133 - accuracy: 0.4208\n",
            "Epoch 316: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.4133 - accuracy: 0.4208 - val_loss: 3.4619 - val_accuracy: 0.4429\n",
            "Epoch 317/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5399 - accuracy: 0.3844\n",
            "Epoch 317: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.5399 - accuracy: 0.3844 - val_loss: 3.4302 - val_accuracy: 0.4571\n",
            "Epoch 318/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4953 - accuracy: 0.3932\n",
            "Epoch 318: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.4953 - accuracy: 0.3932 - val_loss: 3.5103 - val_accuracy: 0.4429\n",
            "Epoch 319/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4968 - accuracy: 0.3867\n",
            "Epoch 319: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.4968 - accuracy: 0.3867 - val_loss: 3.4947 - val_accuracy: 0.4524\n",
            "Epoch 320/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4368 - accuracy: 0.4002\n",
            "Epoch 320: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.4368 - accuracy: 0.4002 - val_loss: 3.4052 - val_accuracy: 0.4524\n",
            "Epoch 321/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4440 - accuracy: 0.3950\n",
            "Epoch 321: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.4440 - accuracy: 0.3950 - val_loss: 3.4013 - val_accuracy: 0.4667\n",
            "Epoch 322/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4082 - accuracy: 0.4161\n",
            "Epoch 322: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 426ms/step - loss: 3.4082 - accuracy: 0.4161 - val_loss: 3.4034 - val_accuracy: 0.4857\n",
            "Epoch 323/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4215 - accuracy: 0.4120\n",
            "Epoch 323: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.4215 - accuracy: 0.4120 - val_loss: 3.3885 - val_accuracy: 0.4571\n",
            "Epoch 324/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4430 - accuracy: 0.4008\n",
            "Epoch 324: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.4430 - accuracy: 0.4008 - val_loss: 3.3909 - val_accuracy: 0.4667\n",
            "Epoch 325/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4818 - accuracy: 0.3938\n",
            "Epoch 325: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.4818 - accuracy: 0.3938 - val_loss: 3.4588 - val_accuracy: 0.4810\n",
            "Epoch 326/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4282 - accuracy: 0.4026\n",
            "Epoch 326: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.4282 - accuracy: 0.4026 - val_loss: 3.4352 - val_accuracy: 0.4524\n",
            "Epoch 327/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4893 - accuracy: 0.3973\n",
            "Epoch 327: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 419ms/step - loss: 3.4893 - accuracy: 0.3973 - val_loss: 3.4366 - val_accuracy: 0.4429\n",
            "Epoch 328/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4547 - accuracy: 0.3996\n",
            "Epoch 328: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.4547 - accuracy: 0.3996 - val_loss: 3.5093 - val_accuracy: 0.4476\n",
            "Epoch 329/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4915 - accuracy: 0.4067\n",
            "Epoch 329: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.4915 - accuracy: 0.4067 - val_loss: 3.4539 - val_accuracy: 0.4857\n",
            "Epoch 330/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4546 - accuracy: 0.4032\n",
            "Epoch 330: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.4546 - accuracy: 0.4032 - val_loss: 3.4470 - val_accuracy: 0.4905\n",
            "Epoch 331/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4424 - accuracy: 0.4061\n",
            "Epoch 331: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.4424 - accuracy: 0.4061 - val_loss: 3.4156 - val_accuracy: 0.4714\n",
            "Epoch 332/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5032 - accuracy: 0.3985\n",
            "Epoch 332: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.5032 - accuracy: 0.3985 - val_loss: 3.4474 - val_accuracy: 0.4619\n",
            "Epoch 333/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5377 - accuracy: 0.4043\n",
            "Epoch 333: val_accuracy did not improve from 0.49524\n",
            "27/27 [==============================] - 12s 453ms/step - loss: 3.5377 - accuracy: 0.4043 - val_loss: 3.5607 - val_accuracy: 0.4905\n",
            "Epoch 334/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5228 - accuracy: 0.4131\n",
            "Epoch 334: val_accuracy improved from 0.49524 to 0.50952, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 992ms/step - loss: 3.5228 - accuracy: 0.4131 - val_loss: 3.4241 - val_accuracy: 0.5095\n",
            "Epoch 335/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4680 - accuracy: 0.4020\n",
            "Epoch 335: val_accuracy did not improve from 0.50952\n",
            "27/27 [==============================] - 12s 425ms/step - loss: 3.4680 - accuracy: 0.4020 - val_loss: 3.4338 - val_accuracy: 0.4667\n",
            "Epoch 336/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4635 - accuracy: 0.4237\n",
            "Epoch 336: val_accuracy did not improve from 0.50952\n",
            "27/27 [==============================] - 11s 412ms/step - loss: 3.4635 - accuracy: 0.4237 - val_loss: 3.5524 - val_accuracy: 0.4524\n",
            "Epoch 337/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4743 - accuracy: 0.4002\n",
            "Epoch 337: val_accuracy did not improve from 0.50952\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.4743 - accuracy: 0.4002 - val_loss: 3.4813 - val_accuracy: 0.5048\n",
            "Epoch 338/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4622 - accuracy: 0.4038\n",
            "Epoch 338: val_accuracy did not improve from 0.50952\n",
            "27/27 [==============================] - 11s 422ms/step - loss: 3.4622 - accuracy: 0.4038 - val_loss: 3.4737 - val_accuracy: 0.4524\n",
            "Epoch 339/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5301 - accuracy: 0.4008\n",
            "Epoch 339: val_accuracy improved from 0.50952 to 0.51429, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 964ms/step - loss: 3.5301 - accuracy: 0.4008 - val_loss: 3.4550 - val_accuracy: 0.5143\n",
            "Epoch 340/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4225 - accuracy: 0.4090\n",
            "Epoch 340: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 12s 424ms/step - loss: 3.4225 - accuracy: 0.4090 - val_loss: 3.4859 - val_accuracy: 0.4667\n",
            "Epoch 341/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4681 - accuracy: 0.4090\n",
            "Epoch 341: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.4681 - accuracy: 0.4090 - val_loss: 3.4785 - val_accuracy: 0.4476\n",
            "Epoch 342/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4504 - accuracy: 0.4014\n",
            "Epoch 342: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.4504 - accuracy: 0.4014 - val_loss: 3.4415 - val_accuracy: 0.4619\n",
            "Epoch 343/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5168 - accuracy: 0.3815\n",
            "Epoch 343: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.5168 - accuracy: 0.3815 - val_loss: 3.4380 - val_accuracy: 0.4762\n",
            "Epoch 344/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4818 - accuracy: 0.3885\n",
            "Epoch 344: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.4818 - accuracy: 0.3885 - val_loss: 3.4790 - val_accuracy: 0.4286\n",
            "Epoch 345/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4641 - accuracy: 0.4079\n",
            "Epoch 345: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.4641 - accuracy: 0.4079 - val_loss: 3.5145 - val_accuracy: 0.4476\n",
            "Epoch 346/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4357 - accuracy: 0.4137\n",
            "Epoch 346: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 423ms/step - loss: 3.4357 - accuracy: 0.4137 - val_loss: 3.4811 - val_accuracy: 0.4381\n",
            "Epoch 347/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4473 - accuracy: 0.4308\n",
            "Epoch 347: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.4473 - accuracy: 0.4308 - val_loss: 3.4259 - val_accuracy: 0.4762\n",
            "Epoch 348/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.3951 - accuracy: 0.4249\n",
            "Epoch 348: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.3951 - accuracy: 0.4249 - val_loss: 3.4501 - val_accuracy: 0.5000\n",
            "Epoch 349/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4034 - accuracy: 0.4190\n",
            "Epoch 349: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 13s 465ms/step - loss: 3.4034 - accuracy: 0.4190 - val_loss: 3.4708 - val_accuracy: 0.4857\n",
            "Epoch 350/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4247 - accuracy: 0.4120\n",
            "Epoch 350: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.4247 - accuracy: 0.4120 - val_loss: 3.4371 - val_accuracy: 0.4762\n",
            "Epoch 351/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4126 - accuracy: 0.4255\n",
            "Epoch 351: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.4126 - accuracy: 0.4255 - val_loss: 3.4489 - val_accuracy: 0.4571\n",
            "Epoch 352/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4207 - accuracy: 0.4079\n",
            "Epoch 352: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.4207 - accuracy: 0.4079 - val_loss: 3.4404 - val_accuracy: 0.4429\n",
            "Epoch 353/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4484 - accuracy: 0.3979\n",
            "Epoch 353: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.4484 - accuracy: 0.3979 - val_loss: 3.4370 - val_accuracy: 0.4571\n",
            "Epoch 354/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4071 - accuracy: 0.4173\n",
            "Epoch 354: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.4071 - accuracy: 0.4173 - val_loss: 3.4074 - val_accuracy: 0.5000\n",
            "Epoch 355/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4306 - accuracy: 0.4219\n",
            "Epoch 355: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.4306 - accuracy: 0.4219 - val_loss: 3.4228 - val_accuracy: 0.4952\n",
            "Epoch 356/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4579 - accuracy: 0.4096\n",
            "Epoch 356: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 414ms/step - loss: 3.4579 - accuracy: 0.4096 - val_loss: 3.5006 - val_accuracy: 0.4571\n",
            "Epoch 357/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4827 - accuracy: 0.3973\n",
            "Epoch 357: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 419ms/step - loss: 3.4827 - accuracy: 0.3973 - val_loss: 3.4557 - val_accuracy: 0.4571\n",
            "Epoch 358/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4571 - accuracy: 0.4161\n",
            "Epoch 358: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 411ms/step - loss: 3.4571 - accuracy: 0.4161 - val_loss: 3.4771 - val_accuracy: 0.4381\n",
            "Epoch 359/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4694 - accuracy: 0.4143\n",
            "Epoch 359: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.4694 - accuracy: 0.4143 - val_loss: 3.5403 - val_accuracy: 0.4762\n",
            "Epoch 360/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4552 - accuracy: 0.4120\n",
            "Epoch 360: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.4552 - accuracy: 0.4120 - val_loss: 3.4794 - val_accuracy: 0.4619\n",
            "Epoch 361/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.3939 - accuracy: 0.4190\n",
            "Epoch 361: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.3939 - accuracy: 0.4190 - val_loss: 3.4412 - val_accuracy: 0.4619\n",
            "Epoch 362/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4164 - accuracy: 0.4208\n",
            "Epoch 362: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 414ms/step - loss: 3.4164 - accuracy: 0.4208 - val_loss: 3.4526 - val_accuracy: 0.4714\n",
            "Epoch 363/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4653 - accuracy: 0.4032\n",
            "Epoch 363: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.4653 - accuracy: 0.4032 - val_loss: 3.4365 - val_accuracy: 0.4619\n",
            "Epoch 364/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4569 - accuracy: 0.4032\n",
            "Epoch 364: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 419ms/step - loss: 3.4569 - accuracy: 0.4032 - val_loss: 3.4173 - val_accuracy: 0.5048\n",
            "Epoch 365/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4211 - accuracy: 0.4302\n",
            "Epoch 365: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.4211 - accuracy: 0.4302 - val_loss: 3.4153 - val_accuracy: 0.5048\n",
            "Epoch 366/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4146 - accuracy: 0.4202\n",
            "Epoch 366: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.4146 - accuracy: 0.4202 - val_loss: 3.4223 - val_accuracy: 0.4810\n",
            "Epoch 367/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4473 - accuracy: 0.4149\n",
            "Epoch 367: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.4473 - accuracy: 0.4149 - val_loss: 3.4491 - val_accuracy: 0.4952\n",
            "Epoch 368/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4986 - accuracy: 0.4085\n",
            "Epoch 368: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 12s 427ms/step - loss: 3.4986 - accuracy: 0.4085 - val_loss: 3.5040 - val_accuracy: 0.4571\n",
            "Epoch 369/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4856 - accuracy: 0.4284\n",
            "Epoch 369: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.4856 - accuracy: 0.4284 - val_loss: 3.4277 - val_accuracy: 0.4762\n",
            "Epoch 370/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4651 - accuracy: 0.4108\n",
            "Epoch 370: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 12s 424ms/step - loss: 3.4651 - accuracy: 0.4108 - val_loss: 3.4573 - val_accuracy: 0.4810\n",
            "Epoch 371/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4768 - accuracy: 0.4190\n",
            "Epoch 371: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 12s 425ms/step - loss: 3.4768 - accuracy: 0.4190 - val_loss: 3.4464 - val_accuracy: 0.4810\n",
            "Epoch 372/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4423 - accuracy: 0.4360\n",
            "Epoch 372: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.4423 - accuracy: 0.4360 - val_loss: 3.5802 - val_accuracy: 0.5048\n",
            "Epoch 373/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4664 - accuracy: 0.4173\n",
            "Epoch 373: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 414ms/step - loss: 3.4664 - accuracy: 0.4173 - val_loss: 3.5189 - val_accuracy: 0.4619\n",
            "Epoch 374/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4356 - accuracy: 0.4196\n",
            "Epoch 374: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.4356 - accuracy: 0.4196 - val_loss: 3.4481 - val_accuracy: 0.4571\n",
            "Epoch 375/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4422 - accuracy: 0.4325\n",
            "Epoch 375: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 12s 424ms/step - loss: 3.4422 - accuracy: 0.4325 - val_loss: 3.4042 - val_accuracy: 0.4857\n",
            "Epoch 376/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4257 - accuracy: 0.4396\n",
            "Epoch 376: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 424ms/step - loss: 3.4257 - accuracy: 0.4396 - val_loss: 3.4836 - val_accuracy: 0.4810\n",
            "Epoch 377/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4327 - accuracy: 0.4255\n",
            "Epoch 377: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 12s 428ms/step - loss: 3.4327 - accuracy: 0.4255 - val_loss: 3.4549 - val_accuracy: 0.4952\n",
            "Epoch 378/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4466 - accuracy: 0.4196\n",
            "Epoch 378: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.4466 - accuracy: 0.4196 - val_loss: 3.3804 - val_accuracy: 0.4810\n",
            "Epoch 379/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4589 - accuracy: 0.4178\n",
            "Epoch 379: val_accuracy did not improve from 0.51429\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.4589 - accuracy: 0.4178 - val_loss: 3.5602 - val_accuracy: 0.4429\n",
            "Epoch 380/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4300 - accuracy: 0.4167\n",
            "Epoch 380: val_accuracy improved from 0.51429 to 0.51905, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 996ms/step - loss: 3.4300 - accuracy: 0.4167 - val_loss: 3.3731 - val_accuracy: 0.5190\n",
            "Epoch 381/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4156 - accuracy: 0.4284\n",
            "Epoch 381: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.4156 - accuracy: 0.4284 - val_loss: 3.4077 - val_accuracy: 0.5000\n",
            "Epoch 382/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5064 - accuracy: 0.4296\n",
            "Epoch 382: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.5064 - accuracy: 0.4296 - val_loss: 3.4027 - val_accuracy: 0.4952\n",
            "Epoch 383/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4434 - accuracy: 0.4278\n",
            "Epoch 383: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 12s 427ms/step - loss: 3.4434 - accuracy: 0.4278 - val_loss: 3.4553 - val_accuracy: 0.5048\n",
            "Epoch 384/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4414 - accuracy: 0.4313\n",
            "Epoch 384: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 13s 469ms/step - loss: 3.4414 - accuracy: 0.4313 - val_loss: 3.3990 - val_accuracy: 0.5000\n",
            "Epoch 385/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4183 - accuracy: 0.4261\n",
            "Epoch 385: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 12s 426ms/step - loss: 3.4183 - accuracy: 0.4261 - val_loss: 3.4212 - val_accuracy: 0.4524\n",
            "Epoch 386/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4472 - accuracy: 0.4114\n",
            "Epoch 386: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 12s 429ms/step - loss: 3.4472 - accuracy: 0.4114 - val_loss: 3.3482 - val_accuracy: 0.5000\n",
            "Epoch 387/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4196 - accuracy: 0.4155\n",
            "Epoch 387: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 12s 427ms/step - loss: 3.4196 - accuracy: 0.4155 - val_loss: 3.5090 - val_accuracy: 0.4762\n",
            "Epoch 388/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4581 - accuracy: 0.4190\n",
            "Epoch 388: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 11s 422ms/step - loss: 3.4581 - accuracy: 0.4190 - val_loss: 3.4498 - val_accuracy: 0.5048\n",
            "Epoch 389/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5033 - accuracy: 0.4161\n",
            "Epoch 389: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 11s 419ms/step - loss: 3.5033 - accuracy: 0.4161 - val_loss: 3.5087 - val_accuracy: 0.4571\n",
            "Epoch 390/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4325 - accuracy: 0.4249\n",
            "Epoch 390: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 12s 424ms/step - loss: 3.4325 - accuracy: 0.4249 - val_loss: 3.4222 - val_accuracy: 0.5095\n",
            "Epoch 391/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4097 - accuracy: 0.4308\n",
            "Epoch 391: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 11s 422ms/step - loss: 3.4097 - accuracy: 0.4308 - val_loss: 3.4152 - val_accuracy: 0.4857\n",
            "Epoch 392/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4974 - accuracy: 0.4061\n",
            "Epoch 392: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 12s 424ms/step - loss: 3.4974 - accuracy: 0.4061 - val_loss: 3.4886 - val_accuracy: 0.4714\n",
            "Epoch 393/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4301 - accuracy: 0.4290\n",
            "Epoch 393: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 12s 427ms/step - loss: 3.4301 - accuracy: 0.4290 - val_loss: 3.4136 - val_accuracy: 0.5000\n",
            "Epoch 394/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4009 - accuracy: 0.4366\n",
            "Epoch 394: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.4009 - accuracy: 0.4366 - val_loss: 3.4066 - val_accuracy: 0.4762\n",
            "Epoch 395/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4771 - accuracy: 0.4225\n",
            "Epoch 395: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 11s 422ms/step - loss: 3.4771 - accuracy: 0.4225 - val_loss: 3.4610 - val_accuracy: 0.4619\n",
            "Epoch 396/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4193 - accuracy: 0.4284\n",
            "Epoch 396: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 11s 422ms/step - loss: 3.4193 - accuracy: 0.4284 - val_loss: 3.4261 - val_accuracy: 0.5000\n",
            "Epoch 397/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4154 - accuracy: 0.4419\n",
            "Epoch 397: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 11s 423ms/step - loss: 3.4154 - accuracy: 0.4419 - val_loss: 3.4300 - val_accuracy: 0.5000\n",
            "Epoch 398/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4341 - accuracy: 0.4319\n",
            "Epoch 398: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 12s 426ms/step - loss: 3.4341 - accuracy: 0.4319 - val_loss: 3.4948 - val_accuracy: 0.4714\n",
            "Epoch 399/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5262 - accuracy: 0.4073\n",
            "Epoch 399: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 12s 427ms/step - loss: 3.5262 - accuracy: 0.4073 - val_loss: 3.4746 - val_accuracy: 0.4810\n",
            "Epoch 400/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4788 - accuracy: 0.4384\n",
            "Epoch 400: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 12s 428ms/step - loss: 3.4788 - accuracy: 0.4384 - val_loss: 3.3822 - val_accuracy: 0.5190\n",
            "Epoch 401/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4732 - accuracy: 0.4208\n",
            "Epoch 401: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.4732 - accuracy: 0.4208 - val_loss: 3.4167 - val_accuracy: 0.4714\n",
            "Epoch 402/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4857 - accuracy: 0.4313\n",
            "Epoch 402: val_accuracy did not improve from 0.51905\n",
            "27/27 [==============================] - 12s 428ms/step - loss: 3.4857 - accuracy: 0.4313 - val_loss: 3.4746 - val_accuracy: 0.4810\n",
            "Epoch 403/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4175 - accuracy: 0.4190\n",
            "Epoch 403: val_accuracy improved from 0.51905 to 0.52381, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 27s 1s/step - loss: 3.4175 - accuracy: 0.4190 - val_loss: 3.3808 - val_accuracy: 0.5238\n",
            "Epoch 404/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4885 - accuracy: 0.4196\n",
            "Epoch 404: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 11s 422ms/step - loss: 3.4885 - accuracy: 0.4196 - val_loss: 3.4185 - val_accuracy: 0.4667\n",
            "Epoch 405/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4703 - accuracy: 0.4272\n",
            "Epoch 405: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 11s 419ms/step - loss: 3.4703 - accuracy: 0.4272 - val_loss: 3.4345 - val_accuracy: 0.4905\n",
            "Epoch 406/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4014 - accuracy: 0.4378\n",
            "Epoch 406: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 11s 422ms/step - loss: 3.4014 - accuracy: 0.4378 - val_loss: 3.4336 - val_accuracy: 0.5048\n",
            "Epoch 407/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4649 - accuracy: 0.4178\n",
            "Epoch 407: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 12s 425ms/step - loss: 3.4649 - accuracy: 0.4178 - val_loss: 3.4074 - val_accuracy: 0.5190\n",
            "Epoch 408/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4524 - accuracy: 0.4214\n",
            "Epoch 408: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 12s 424ms/step - loss: 3.4524 - accuracy: 0.4214 - val_loss: 3.4036 - val_accuracy: 0.4857\n",
            "Epoch 409/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4502 - accuracy: 0.4407\n",
            "Epoch 409: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 12s 427ms/step - loss: 3.4502 - accuracy: 0.4407 - val_loss: 3.4343 - val_accuracy: 0.5095\n",
            "Epoch 410/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4354 - accuracy: 0.4360\n",
            "Epoch 410: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 11s 422ms/step - loss: 3.4354 - accuracy: 0.4360 - val_loss: 3.3987 - val_accuracy: 0.5190\n",
            "Epoch 411/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4501 - accuracy: 0.4237\n",
            "Epoch 411: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 12s 426ms/step - loss: 3.4501 - accuracy: 0.4237 - val_loss: 3.3965 - val_accuracy: 0.5190\n",
            "Epoch 412/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4047 - accuracy: 0.4366\n",
            "Epoch 412: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.4047 - accuracy: 0.4366 - val_loss: 3.3939 - val_accuracy: 0.5095\n",
            "Epoch 413/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.3768 - accuracy: 0.4372\n",
            "Epoch 413: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.3768 - accuracy: 0.4372 - val_loss: 3.4158 - val_accuracy: 0.4905\n",
            "Epoch 414/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4238 - accuracy: 0.4478\n",
            "Epoch 414: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.4238 - accuracy: 0.4478 - val_loss: 3.4073 - val_accuracy: 0.4952\n",
            "Epoch 415/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4143 - accuracy: 0.4448\n",
            "Epoch 415: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 11s 423ms/step - loss: 3.4143 - accuracy: 0.4448 - val_loss: 3.4360 - val_accuracy: 0.4810\n",
            "Epoch 416/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4471 - accuracy: 0.4202\n",
            "Epoch 416: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 11s 426ms/step - loss: 3.4471 - accuracy: 0.4202 - val_loss: 3.5007 - val_accuracy: 0.4762\n",
            "Epoch 417/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4337 - accuracy: 0.4313\n",
            "Epoch 417: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 11s 422ms/step - loss: 3.4337 - accuracy: 0.4313 - val_loss: 3.4877 - val_accuracy: 0.4381\n",
            "Epoch 418/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4476 - accuracy: 0.4331\n",
            "Epoch 418: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 11s 419ms/step - loss: 3.4476 - accuracy: 0.4331 - val_loss: 3.5057 - val_accuracy: 0.4619\n",
            "Epoch 419/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4409 - accuracy: 0.4272\n",
            "Epoch 419: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 12s 424ms/step - loss: 3.4409 - accuracy: 0.4272 - val_loss: 3.4654 - val_accuracy: 0.5143\n",
            "Epoch 420/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4719 - accuracy: 0.4266\n",
            "Epoch 420: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.4719 - accuracy: 0.4266 - val_loss: 3.4709 - val_accuracy: 0.4429\n",
            "Epoch 421/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5102 - accuracy: 0.4102\n",
            "Epoch 421: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 12s 429ms/step - loss: 3.5102 - accuracy: 0.4102 - val_loss: 3.5153 - val_accuracy: 0.4571\n",
            "Epoch 422/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4912 - accuracy: 0.4202\n",
            "Epoch 422: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 12s 429ms/step - loss: 3.4912 - accuracy: 0.4202 - val_loss: 3.4621 - val_accuracy: 0.4905\n",
            "Epoch 423/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4539 - accuracy: 0.4425\n",
            "Epoch 423: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 11s 422ms/step - loss: 3.4539 - accuracy: 0.4425 - val_loss: 3.4005 - val_accuracy: 0.5238\n",
            "Epoch 424/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4551 - accuracy: 0.4155\n",
            "Epoch 424: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.4551 - accuracy: 0.4155 - val_loss: 3.4666 - val_accuracy: 0.4857\n",
            "Epoch 425/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4572 - accuracy: 0.4137\n",
            "Epoch 425: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.4572 - accuracy: 0.4137 - val_loss: 3.4237 - val_accuracy: 0.4714\n",
            "Epoch 426/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4039 - accuracy: 0.4384\n",
            "Epoch 426: val_accuracy did not improve from 0.52381\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.4039 - accuracy: 0.4384 - val_loss: 3.4128 - val_accuracy: 0.5190\n",
            "Epoch 427/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4023 - accuracy: 0.4513\n",
            "Epoch 427: val_accuracy improved from 0.52381 to 0.53810, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 972ms/step - loss: 3.4023 - accuracy: 0.4513 - val_loss: 3.4196 - val_accuracy: 0.5381\n",
            "Epoch 428/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4271 - accuracy: 0.4284\n",
            "Epoch 428: val_accuracy did not improve from 0.53810\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.4271 - accuracy: 0.4284 - val_loss: 3.3861 - val_accuracy: 0.4952\n",
            "Epoch 429/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.3741 - accuracy: 0.4531\n",
            "Epoch 429: val_accuracy did not improve from 0.53810\n",
            "27/27 [==============================] - 12s 431ms/step - loss: 3.3741 - accuracy: 0.4531 - val_loss: 3.4621 - val_accuracy: 0.4905\n",
            "Epoch 430/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.3866 - accuracy: 0.4484\n",
            "Epoch 430: val_accuracy did not improve from 0.53810\n",
            "27/27 [==============================] - 12s 428ms/step - loss: 3.3866 - accuracy: 0.4484 - val_loss: 3.3961 - val_accuracy: 0.5190\n",
            "Epoch 431/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4162 - accuracy: 0.4407\n",
            "Epoch 431: val_accuracy did not improve from 0.53810\n",
            "27/27 [==============================] - 12s 427ms/step - loss: 3.4162 - accuracy: 0.4407 - val_loss: 3.5572 - val_accuracy: 0.4524\n",
            "Epoch 432/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4694 - accuracy: 0.4313\n",
            "Epoch 432: val_accuracy did not improve from 0.53810\n",
            "27/27 [==============================] - 12s 425ms/step - loss: 3.4694 - accuracy: 0.4313 - val_loss: 3.4443 - val_accuracy: 0.5095\n",
            "Epoch 433/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4443 - accuracy: 0.4296\n",
            "Epoch 433: val_accuracy did not improve from 0.53810\n",
            "27/27 [==============================] - 11s 423ms/step - loss: 3.4443 - accuracy: 0.4296 - val_loss: 3.5432 - val_accuracy: 0.4762\n",
            "Epoch 434/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5003 - accuracy: 0.4484\n",
            "Epoch 434: val_accuracy did not improve from 0.53810\n",
            "27/27 [==============================] - 12s 427ms/step - loss: 3.5003 - accuracy: 0.4484 - val_loss: 3.4943 - val_accuracy: 0.4810\n",
            "Epoch 435/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4664 - accuracy: 0.4466\n",
            "Epoch 435: val_accuracy did not improve from 0.53810\n",
            "27/27 [==============================] - 11s 419ms/step - loss: 3.4664 - accuracy: 0.4466 - val_loss: 3.3709 - val_accuracy: 0.5238\n",
            "Epoch 436/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4455 - accuracy: 0.4472\n",
            "Epoch 436: val_accuracy did not improve from 0.53810\n",
            "27/27 [==============================] - 12s 436ms/step - loss: 3.4455 - accuracy: 0.4472 - val_loss: 3.4319 - val_accuracy: 0.5286\n",
            "Epoch 437/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4510 - accuracy: 0.4284\n",
            "Epoch 437: val_accuracy did not improve from 0.53810\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.4510 - accuracy: 0.4284 - val_loss: 3.4433 - val_accuracy: 0.4952\n",
            "Epoch 438/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4923 - accuracy: 0.4413\n",
            "Epoch 438: val_accuracy did not improve from 0.53810\n",
            "27/27 [==============================] - 11s 423ms/step - loss: 3.4923 - accuracy: 0.4413 - val_loss: 3.4644 - val_accuracy: 0.4714\n",
            "Epoch 439/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4321 - accuracy: 0.4413\n",
            "Epoch 439: val_accuracy did not improve from 0.53810\n",
            "27/27 [==============================] - 12s 426ms/step - loss: 3.4321 - accuracy: 0.4413 - val_loss: 3.4571 - val_accuracy: 0.4857\n",
            "Epoch 440/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4778 - accuracy: 0.4372\n",
            "Epoch 440: val_accuracy did not improve from 0.53810\n",
            "27/27 [==============================] - 12s 428ms/step - loss: 3.4778 - accuracy: 0.4372 - val_loss: 3.4428 - val_accuracy: 0.5000\n",
            "Epoch 441/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4692 - accuracy: 0.4360\n",
            "Epoch 441: val_accuracy did not improve from 0.53810\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.4692 - accuracy: 0.4360 - val_loss: 3.4000 - val_accuracy: 0.5238\n",
            "Epoch 442/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4699 - accuracy: 0.4542\n",
            "Epoch 442: val_accuracy improved from 0.53810 to 0.54286, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 995ms/step - loss: 3.4699 - accuracy: 0.4542 - val_loss: 3.4584 - val_accuracy: 0.5429\n",
            "Epoch 443/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4555 - accuracy: 0.4484\n",
            "Epoch 443: val_accuracy did not improve from 0.54286\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.4555 - accuracy: 0.4484 - val_loss: 3.4033 - val_accuracy: 0.5048\n",
            "Epoch 444/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4325 - accuracy: 0.4495\n",
            "Epoch 444: val_accuracy did not improve from 0.54286\n",
            "27/27 [==============================] - 12s 426ms/step - loss: 3.4325 - accuracy: 0.4495 - val_loss: 3.4468 - val_accuracy: 0.5095\n",
            "Epoch 445/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4168 - accuracy: 0.4448\n",
            "Epoch 445: val_accuracy did not improve from 0.54286\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.4168 - accuracy: 0.4448 - val_loss: 3.4487 - val_accuracy: 0.5143\n",
            "Epoch 446/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.3721 - accuracy: 0.4642\n",
            "Epoch 446: val_accuracy did not improve from 0.54286\n",
            "27/27 [==============================] - 11s 414ms/step - loss: 3.3721 - accuracy: 0.4642 - val_loss: 3.5472 - val_accuracy: 0.4952\n",
            "Epoch 447/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4484 - accuracy: 0.4495\n",
            "Epoch 447: val_accuracy did not improve from 0.54286\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.4484 - accuracy: 0.4495 - val_loss: 3.4183 - val_accuracy: 0.5381\n",
            "Epoch 448/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4730 - accuracy: 0.4390\n",
            "Epoch 448: val_accuracy did not improve from 0.54286\n",
            "27/27 [==============================] - 11s 422ms/step - loss: 3.4730 - accuracy: 0.4390 - val_loss: 3.5076 - val_accuracy: 0.4905\n",
            "Epoch 449/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4379 - accuracy: 0.4360\n",
            "Epoch 449: val_accuracy did not improve from 0.54286\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.4379 - accuracy: 0.4360 - val_loss: 3.4771 - val_accuracy: 0.5095\n",
            "Epoch 450/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.5098 - accuracy: 0.4325\n",
            "Epoch 450: val_accuracy did not improve from 0.54286\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.5098 - accuracy: 0.4325 - val_loss: 3.5265 - val_accuracy: 0.4810\n",
            "Epoch 451/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4497 - accuracy: 0.4390\n",
            "Epoch 451: val_accuracy did not improve from 0.54286\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.4497 - accuracy: 0.4390 - val_loss: 3.4684 - val_accuracy: 0.5286\n",
            "Epoch 452/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4493 - accuracy: 0.4278\n",
            "Epoch 452: val_accuracy did not improve from 0.54286\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.4493 - accuracy: 0.4278 - val_loss: 3.5143 - val_accuracy: 0.4952\n",
            "Epoch 453/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4331 - accuracy: 0.4384\n",
            "Epoch 453: val_accuracy did not improve from 0.54286\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.4331 - accuracy: 0.4384 - val_loss: 3.4637 - val_accuracy: 0.5190\n",
            "Epoch 454/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4577 - accuracy: 0.4572\n",
            "Epoch 454: val_accuracy did not improve from 0.54286\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.4577 - accuracy: 0.4572 - val_loss: 3.4619 - val_accuracy: 0.5190\n",
            "Epoch 455/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4093 - accuracy: 0.4442\n",
            "Epoch 455: val_accuracy did not improve from 0.54286\n",
            "27/27 [==============================] - 12s 431ms/step - loss: 3.4093 - accuracy: 0.4442 - val_loss: 3.4730 - val_accuracy: 0.5333\n",
            "Epoch 456/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4596 - accuracy: 0.4396\n",
            "Epoch 456: val_accuracy did not improve from 0.54286\n",
            "27/27 [==============================] - 11s 422ms/step - loss: 3.4596 - accuracy: 0.4396 - val_loss: 3.4157 - val_accuracy: 0.5143\n",
            "Epoch 457/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4370 - accuracy: 0.4495\n",
            "Epoch 457: val_accuracy improved from 0.54286 to 0.54762, saving model to Best_facecelb_model_val.h5\n",
            "27/27 [==============================] - 26s 968ms/step - loss: 3.4370 - accuracy: 0.4495 - val_loss: 3.4215 - val_accuracy: 0.5476\n",
            "Epoch 458/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4093 - accuracy: 0.4589\n",
            "Epoch 458: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 419ms/step - loss: 3.4093 - accuracy: 0.4589 - val_loss: 3.6150 - val_accuracy: 0.4857\n",
            "Epoch 459/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4695 - accuracy: 0.4354\n",
            "Epoch 459: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.4695 - accuracy: 0.4354 - val_loss: 3.5296 - val_accuracy: 0.4762\n",
            "Epoch 460/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4374 - accuracy: 0.4531\n",
            "Epoch 460: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.4374 - accuracy: 0.4531 - val_loss: 3.4981 - val_accuracy: 0.5143\n",
            "Epoch 461/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4370 - accuracy: 0.4613\n",
            "Epoch 461: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.4370 - accuracy: 0.4613 - val_loss: 3.5045 - val_accuracy: 0.4857\n",
            "Epoch 462/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4904 - accuracy: 0.4384\n",
            "Epoch 462: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 422ms/step - loss: 3.4904 - accuracy: 0.4384 - val_loss: 3.4656 - val_accuracy: 0.4905\n",
            "Epoch 463/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4566 - accuracy: 0.4384\n",
            "Epoch 463: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.4566 - accuracy: 0.4384 - val_loss: 3.5273 - val_accuracy: 0.4810\n",
            "Epoch 464/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4333 - accuracy: 0.4624\n",
            "Epoch 464: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.4333 - accuracy: 0.4624 - val_loss: 3.4842 - val_accuracy: 0.5429\n",
            "Epoch 465/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4340 - accuracy: 0.4507\n",
            "Epoch 465: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 12s 426ms/step - loss: 3.4340 - accuracy: 0.4507 - val_loss: 3.5233 - val_accuracy: 0.5286\n",
            "Epoch 466/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4622 - accuracy: 0.4583\n",
            "Epoch 466: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 12s 458ms/step - loss: 3.4622 - accuracy: 0.4583 - val_loss: 3.5653 - val_accuracy: 0.4952\n",
            "Epoch 467/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4735 - accuracy: 0.4525\n",
            "Epoch 467: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 428ms/step - loss: 3.4735 - accuracy: 0.4525 - val_loss: 3.4698 - val_accuracy: 0.5143\n",
            "Epoch 468/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4819 - accuracy: 0.4378\n",
            "Epoch 468: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.4819 - accuracy: 0.4378 - val_loss: 3.5584 - val_accuracy: 0.5095\n",
            "Epoch 469/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4930 - accuracy: 0.4372\n",
            "Epoch 469: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 12s 426ms/step - loss: 3.4930 - accuracy: 0.4372 - val_loss: 3.5361 - val_accuracy: 0.4857\n",
            "Epoch 470/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4297 - accuracy: 0.4507\n",
            "Epoch 470: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.4297 - accuracy: 0.4507 - val_loss: 3.4602 - val_accuracy: 0.4905\n",
            "Epoch 471/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4765 - accuracy: 0.4448\n",
            "Epoch 471: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.4765 - accuracy: 0.4448 - val_loss: 3.4311 - val_accuracy: 0.5143\n",
            "Epoch 472/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4245 - accuracy: 0.4396\n",
            "Epoch 472: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.4245 - accuracy: 0.4396 - val_loss: 3.4630 - val_accuracy: 0.4952\n",
            "Epoch 473/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4607 - accuracy: 0.4431\n",
            "Epoch 473: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.4607 - accuracy: 0.4431 - val_loss: 3.5390 - val_accuracy: 0.5095\n",
            "Epoch 474/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4533 - accuracy: 0.4525\n",
            "Epoch 474: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 424ms/step - loss: 3.4533 - accuracy: 0.4525 - val_loss: 3.5577 - val_accuracy: 0.4857\n",
            "Epoch 475/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4149 - accuracy: 0.4460\n",
            "Epoch 475: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.4149 - accuracy: 0.4460 - val_loss: 3.4904 - val_accuracy: 0.5190\n",
            "Epoch 476/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4384 - accuracy: 0.4489\n",
            "Epoch 476: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 422ms/step - loss: 3.4384 - accuracy: 0.4489 - val_loss: 3.4817 - val_accuracy: 0.5095\n",
            "Epoch 477/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4473 - accuracy: 0.4466\n",
            "Epoch 477: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.4473 - accuracy: 0.4466 - val_loss: 3.6638 - val_accuracy: 0.4905\n",
            "Epoch 478/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4470 - accuracy: 0.4437\n",
            "Epoch 478: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 423ms/step - loss: 3.4470 - accuracy: 0.4437 - val_loss: 3.5642 - val_accuracy: 0.4714\n",
            "Epoch 479/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4157 - accuracy: 0.4442\n",
            "Epoch 479: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 12s 424ms/step - loss: 3.4157 - accuracy: 0.4442 - val_loss: 3.5299 - val_accuracy: 0.4952\n",
            "Epoch 480/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4564 - accuracy: 0.4560\n",
            "Epoch 480: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 12s 425ms/step - loss: 3.4564 - accuracy: 0.4560 - val_loss: 3.5075 - val_accuracy: 0.4762\n",
            "Epoch 481/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4477 - accuracy: 0.4478\n",
            "Epoch 481: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 12s 430ms/step - loss: 3.4477 - accuracy: 0.4478 - val_loss: 3.4627 - val_accuracy: 0.5143\n",
            "Epoch 482/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4381 - accuracy: 0.4507\n",
            "Epoch 482: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 423ms/step - loss: 3.4381 - accuracy: 0.4507 - val_loss: 3.4706 - val_accuracy: 0.4952\n",
            "Epoch 483/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4121 - accuracy: 0.4636\n",
            "Epoch 483: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.4121 - accuracy: 0.4636 - val_loss: 3.4459 - val_accuracy: 0.5143\n",
            "Epoch 484/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4020 - accuracy: 0.4507\n",
            "Epoch 484: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 413ms/step - loss: 3.4020 - accuracy: 0.4507 - val_loss: 3.4332 - val_accuracy: 0.4857\n",
            "Epoch 485/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4223 - accuracy: 0.4366\n",
            "Epoch 485: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 422ms/step - loss: 3.4223 - accuracy: 0.4366 - val_loss: 3.4540 - val_accuracy: 0.5333\n",
            "Epoch 486/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4731 - accuracy: 0.4489\n",
            "Epoch 486: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 417ms/step - loss: 3.4731 - accuracy: 0.4489 - val_loss: 3.4504 - val_accuracy: 0.4857\n",
            "Epoch 487/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.3801 - accuracy: 0.4665\n",
            "Epoch 487: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 415ms/step - loss: 3.3801 - accuracy: 0.4665 - val_loss: 3.4921 - val_accuracy: 0.5000\n",
            "Epoch 488/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4716 - accuracy: 0.4407\n",
            "Epoch 488: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 12s 424ms/step - loss: 3.4716 - accuracy: 0.4407 - val_loss: 3.5489 - val_accuracy: 0.4667\n",
            "Epoch 489/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4390 - accuracy: 0.4489\n",
            "Epoch 489: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 419ms/step - loss: 3.4390 - accuracy: 0.4489 - val_loss: 3.6674 - val_accuracy: 0.4667\n",
            "Epoch 490/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4894 - accuracy: 0.4437\n",
            "Epoch 490: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.4894 - accuracy: 0.4437 - val_loss: 3.4492 - val_accuracy: 0.5143\n",
            "Epoch 491/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4075 - accuracy: 0.4478\n",
            "Epoch 491: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 423ms/step - loss: 3.4075 - accuracy: 0.4478 - val_loss: 3.4818 - val_accuracy: 0.5143\n",
            "Epoch 492/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.3670 - accuracy: 0.4660\n",
            "Epoch 492: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 419ms/step - loss: 3.3670 - accuracy: 0.4660 - val_loss: 3.4917 - val_accuracy: 0.5095\n",
            "Epoch 493/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4767 - accuracy: 0.4431\n",
            "Epoch 493: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 12s 426ms/step - loss: 3.4767 - accuracy: 0.4431 - val_loss: 3.5324 - val_accuracy: 0.4857\n",
            "Epoch 494/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.3855 - accuracy: 0.4607\n",
            "Epoch 494: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 423ms/step - loss: 3.3855 - accuracy: 0.4607 - val_loss: 3.5187 - val_accuracy: 0.4952\n",
            "Epoch 495/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4271 - accuracy: 0.4630\n",
            "Epoch 495: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.4271 - accuracy: 0.4630 - val_loss: 3.5968 - val_accuracy: 0.4762\n",
            "Epoch 496/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4557 - accuracy: 0.4577\n",
            "Epoch 496: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 421ms/step - loss: 3.4557 - accuracy: 0.4577 - val_loss: 3.6589 - val_accuracy: 0.4905\n",
            "Epoch 497/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4025 - accuracy: 0.4630\n",
            "Epoch 497: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 12s 454ms/step - loss: 3.4025 - accuracy: 0.4630 - val_loss: 3.5125 - val_accuracy: 0.5333\n",
            "Epoch 498/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4099 - accuracy: 0.4548\n",
            "Epoch 498: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 420ms/step - loss: 3.4099 - accuracy: 0.4548 - val_loss: 3.4887 - val_accuracy: 0.5286\n",
            "Epoch 499/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4085 - accuracy: 0.4636\n",
            "Epoch 499: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 416ms/step - loss: 3.4085 - accuracy: 0.4636 - val_loss: 3.5279 - val_accuracy: 0.5476\n",
            "Epoch 500/500\n",
            "27/27 [==============================] - ETA: 0s - loss: 3.4508 - accuracy: 0.4466\n",
            "Epoch 500: val_accuracy did not improve from 0.54762\n",
            "27/27 [==============================] - 11s 418ms/step - loss: 3.4508 - accuracy: 0.4466 - val_loss: 3.5906 - val_accuracy: 0.4762\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc = face_celeb_train.history['accuracy']\n",
        "val_acc = face_celeb_train.history['val_accuracy']\n",
        "\n",
        "loss = face_celeb_train.history['loss']\n",
        "val_loss = face_celeb_train.history['val_loss']\n",
        "epochs_range=range(500)\n",
        "plt.figure(figsize=(10, 10))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
        "plt.legend(loc='lower right')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "PizehT3b5CEs",
        "outputId": "89a33a48-85cb-48db-d85e-5e52a67cfb42"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 720x720 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Saving model in JSON file \n",
        "from tensorflow.keras.models import model_from_json\n",
        "model_in_json = model.to_json()\n",
        "with open('model.json','w') as json_file:\n",
        "  json_file.write(model_in_json)"
      ],
      "metadata": {
        "id": "DrEJKof19slJ"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Loading model from JSON file\n",
        "model_file = open('model.json','r')\n",
        "json_model=model_file.read()\n",
        "model2=model_from_json(json_model)\n",
        "model2.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKNH3qitMsFa",
        "outputId": "55ce27be-59f8-43fe-edf7-6bd3ca50c5aa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 128, 128, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2D  (None, 64, 64, 16)       0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 64, 64, 16)        0         \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 64, 64, 64)        9280      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPooling  (None, 32, 32, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 32, 32, 256)       147712    \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPooling  (None, 16, 16, 256)      0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 65536)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 4096)              268439552 \n",
            "                                                                 \n",
            " dropout_3 (Dropout)         (None, 4096)              0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1024)              4195328   \n",
            "                                                                 \n",
            " dropout_4 (Dropout)         (None, 1024)              0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 37)                37925     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 272,830,245\n",
            "Trainable params: 272,830,245\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "D6ba4n33O6IX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}